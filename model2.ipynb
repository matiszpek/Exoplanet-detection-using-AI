{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42f1272c",
   "metadata": {},
   "source": [
    "# Exoplanet detection using AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a2e58f",
   "metadata": {},
   "source": [
    "This notebook will explore datasets related to exoplanet detection, specifically the Kepler and TESS missions. We will use Python libraries such as Pandas, NumPy, Matplotlib, and Scikit-learn to analyze the data and build a machine learning model to classify potential exoplanets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e06ae8e",
   "metadata": {},
   "source": [
    "Mas especificamente este notebook es el \"hijo\" de un notebook anterior que se llama \"model.ipynb\" y que contiene el modelo inicial donde se hacen un monton de proceso, pruebas y concluciones pero que fueron todas haciendo la postura de no tomar los false positive, sino que se trataba de un modelo binario (planet, no planet). En este notebook se va a tratar de hacer un modelo que tome en cuenta los false positive y que pueda distinguir entre planetas, false positive y no planetas o la ampliacion del modelo de model.ipnynb a un modelo que pueda reconocer de forma inferida los false positive siendo que pueda reentrenarse con las mismas categorias de salida (planet o no planet) pero esta vez tomando las false positive como no planet y se muestren cierta cantidad den el train y otra en el test pudiendo ser que se muestren el 50% en el train y el restante en el test y ver si de esa forma se encuentra la fina distincion que suponemos se puede lograr entre los false positive y los positive. Creemos que va a ser dificil realizar la distincion ya que haciendo la prueba de este modelo viejo probandolo con todos los datos nos dio que la mayoria de los 1 eran positives pero ademas estaban sumados la mayoria de los false positive, y los 0 eran no planetas, pero no se podia distinguir entre false positive y positive.\n",
    "\n",
    "La idea es que este modelo pueda ser reentrenado con los datos de salida de los modelos anteriores y que pueda ir aprendiendo a distinguir entre false positive y positive, pero que en un principio se entrene con los datos originales pero tomando los false positive como no planetas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4797e2f4",
   "metadata": {},
   "source": [
    "*Exploring the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22b04d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas numpy matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c18aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3bf24b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kepid</th>\n",
       "      <th>kepoi_name</th>\n",
       "      <th>kepler_name</th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_pdisposition</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.01</td>\n",
       "      <td>Kepler-227 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.02</td>\n",
       "      <td>Kepler-227 c</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10811496</td>\n",
       "      <td>K00753.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10848459</td>\n",
       "      <td>K00754.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10854555</td>\n",
       "      <td>K00755.01</td>\n",
       "      <td>Kepler-664 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      kepid kepoi_name   kepler_name koi_disposition koi_pdisposition  \\\n",
       "0  10797460  K00752.01  Kepler-227 b       CONFIRMED        CANDIDATE   \n",
       "1  10797460  K00752.02  Kepler-227 c       CONFIRMED        CANDIDATE   \n",
       "2  10811496  K00753.01           NaN       CANDIDATE        CANDIDATE   \n",
       "3  10848459  K00754.01           NaN  FALSE POSITIVE   FALSE POSITIVE   \n",
       "4  10854555  K00755.01  Kepler-664 b       CONFIRMED        CANDIDATE   \n",
       "\n",
       "   koi_score  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  ...  \\\n",
       "0      1.000              0              0              0              0  ...   \n",
       "1      0.969              0              0              0              0  ...   \n",
       "2      0.000              0              0              0              0  ...   \n",
       "3      0.000              0              1              0              0  ...   \n",
       "4      1.000              0              0              0              0  ...   \n",
       "\n",
       "   koi_steff_err2  koi_slogg  koi_slogg_err1  koi_slogg_err2  koi_srad  \\\n",
       "0           -81.0      4.467           0.064          -0.096     0.927   \n",
       "1           -81.0      4.467           0.064          -0.096     0.927   \n",
       "2          -176.0      4.544           0.044          -0.176     0.868   \n",
       "3          -174.0      4.564           0.053          -0.168     0.791   \n",
       "4          -211.0      4.438           0.070          -0.210     1.046   \n",
       "\n",
       "   koi_srad_err1  koi_srad_err2         ra        dec  koi_kepmag  \n",
       "0          0.105         -0.061  291.93423  48.141651      15.347  \n",
       "1          0.105         -0.061  291.93423  48.141651      15.347  \n",
       "2          0.233         -0.078  297.00482  48.134129      15.436  \n",
       "3          0.201         -0.067  285.53461  48.285210      15.597  \n",
       "4          0.334         -0.133  288.75488  48.226200      15.509  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "#path = r\"C:\\Users\\matir\\OneDrive\\Documentos\\NASA\\Exoplanet detection using AI\\data\\cumulative_2025.10.04_05.21.55.csv\"\n",
    "path = \"data/cumulative_2025.10.04_05.21.55.csv\"\n",
    "df = pd.read_csv(\n",
    "    path,\n",
    "    comment='#',      # ignore metadata lines starting with '#'\n",
    "    engine='python',  # more forgiving parser\n",
    ")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b641103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9564 entries, 0 to 9563\n",
      "Data columns (total 49 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   kepid              9564 non-null   int64  \n",
      " 1   kepoi_name         9564 non-null   object \n",
      " 2   kepler_name        2747 non-null   object \n",
      " 3   koi_disposition    9564 non-null   object \n",
      " 4   koi_pdisposition   9564 non-null   object \n",
      " 5   koi_score          8054 non-null   float64\n",
      " 6   koi_fpflag_nt      9564 non-null   int64  \n",
      " 7   koi_fpflag_ss      9564 non-null   int64  \n",
      " 8   koi_fpflag_co      9564 non-null   int64  \n",
      " 9   koi_fpflag_ec      9564 non-null   int64  \n",
      " 10  koi_period         9564 non-null   float64\n",
      " 11  koi_period_err1    9110 non-null   float64\n",
      " 12  koi_period_err2    9110 non-null   float64\n",
      " 13  koi_time0bk        9564 non-null   float64\n",
      " 14  koi_time0bk_err1   9110 non-null   float64\n",
      " 15  koi_time0bk_err2   9110 non-null   float64\n",
      " 16  koi_impact         9201 non-null   float64\n",
      " 17  koi_impact_err1    9110 non-null   float64\n",
      " 18  koi_impact_err2    9110 non-null   float64\n",
      " 19  koi_duration       9564 non-null   float64\n",
      " 20  koi_duration_err1  9110 non-null   float64\n",
      " 21  koi_duration_err2  9110 non-null   float64\n",
      " 22  koi_depth          9201 non-null   float64\n",
      " 23  koi_depth_err1     9110 non-null   float64\n",
      " 24  koi_depth_err2     9110 non-null   float64\n",
      " 25  koi_prad           9201 non-null   float64\n",
      " 26  koi_prad_err1      9201 non-null   float64\n",
      " 27  koi_prad_err2      9201 non-null   float64\n",
      " 28  koi_teq            9201 non-null   float64\n",
      " 29  koi_teq_err1       0 non-null      float64\n",
      " 30  koi_teq_err2       0 non-null      float64\n",
      " 31  koi_insol          9243 non-null   float64\n",
      " 32  koi_insol_err1     9243 non-null   float64\n",
      " 33  koi_insol_err2     9243 non-null   float64\n",
      " 34  koi_model_snr      9201 non-null   float64\n",
      " 35  koi_tce_plnt_num   9218 non-null   float64\n",
      " 36  koi_tce_delivname  9218 non-null   object \n",
      " 37  koi_steff          9201 non-null   float64\n",
      " 38  koi_steff_err1     9096 non-null   float64\n",
      " 39  koi_steff_err2     9081 non-null   float64\n",
      " 40  koi_slogg          9201 non-null   float64\n",
      " 41  koi_slogg_err1     9096 non-null   float64\n",
      " 42  koi_slogg_err2     9096 non-null   float64\n",
      " 43  koi_srad           9201 non-null   float64\n",
      " 44  koi_srad_err1      9096 non-null   float64\n",
      " 45  koi_srad_err2      9096 non-null   float64\n",
      " 46  ra                 9564 non-null   float64\n",
      " 47  dec                9564 non-null   float64\n",
      " 48  koi_kepmag         9563 non-null   float64\n",
      "dtypes: float64(39), int64(5), object(5)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "koi_teq_err1         9564\n",
       "koi_teq_err2         9564\n",
       "kepler_name          6817\n",
       "koi_score            1510\n",
       "koi_steff_err2        483\n",
       "koi_srad_err1         468\n",
       "koi_steff_err1        468\n",
       "koi_slogg_err2        468\n",
       "koi_slogg_err1        468\n",
       "koi_srad_err2         468\n",
       "koi_time0bk_err1      454\n",
       "koi_period_err1       454\n",
       "koi_period_err2       454\n",
       "koi_time0bk_err2      454\n",
       "koi_impact_err1       454\n",
       "koi_depth_err1        454\n",
       "koi_depth_err2        454\n",
       "koi_duration_err1     454\n",
       "koi_duration_err2     454\n",
       "koi_impact_err2       454\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df.isnull().sum().sort_values(ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a6c7133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "koi_disposition\n",
       "FALSE POSITIVE    4839\n",
       "CONFIRMED         2746\n",
       "CANDIDATE         1979\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['koi_disposition'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "818c87d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_disposition', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
       "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
       "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
       "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
       "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
       "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
       "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
       "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
       "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
       "       'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar columnas irrelevantes y/o vacias\n",
    "columnas_despues = ['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec']\n",
    "cols_drop = ['rowid','kepid','kepoi_name','kepler_name','koi_pdisposition','koi_score','koi_teq_err1','koi_teq_err2','koi_tce_delivname','koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec']\n",
    "df = df.drop(columns=[c for c in cols_drop if c in df.columns])\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06c9266c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribución de Confirmed vs Candidate')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualización de la distribución de las clases\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x='koi_disposition', data=df)\n",
    "plt.title('Distribución de Confirmed vs Candidate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d68cccb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9564, 37) (9564, 36) (9564,)\n",
      "Index(['koi_period', 'koi_period_err1', 'koi_period_err2', 'koi_time0bk',\n",
      "       'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact', 'koi_impact_err1',\n",
      "       'koi_impact_err2', 'koi_duration', 'koi_duration_err1',\n",
      "       'koi_duration_err2', 'koi_depth', 'koi_depth_err1', 'koi_depth_err2',\n",
      "       'koi_prad', 'koi_prad_err1', 'koi_prad_err2', 'koi_teq', 'koi_insol',\n",
      "       'koi_insol_err1', 'koi_insol_err2', 'koi_model_snr', 'koi_tce_plnt_num',\n",
      "       'koi_steff', 'koi_steff_err1', 'koi_steff_err2', 'koi_slogg',\n",
      "       'koi_slogg_err1', 'koi_slogg_err2', 'koi_srad', 'koi_srad_err1',\n",
      "       'koi_srad_err2', 'ra', 'dec', 'koi_kepmag'],\n",
      "      dtype='object')\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Reemplazá NaN con la media\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "df = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "# Split de features y target\n",
    "X = df.drop(columns=['koi_disposition',])\n",
    "y = df['koi_disposition']\n",
    "\n",
    "print(df.shape, X.shape, y.shape)\n",
    "print(X.columns)\n",
    "\n",
    "non_numeric_cols = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "print(non_numeric_cols)  # para ver algunas\n",
    "\n",
    "# Si solo son IDs o etiquetas drop\n",
    "X = X.drop(columns=non_numeric_cols)\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40b31cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd954a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6694, 36) (1435, 36) (1435, 36)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# separar en train, test y validation sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6607ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de y_train:\n",
      "koi_disposition\n",
      "FALSE POSITIVE    3387\n",
      "CONFIRMED         1922\n",
      "CANDIDATE         1385\n",
      "Name: count, dtype: int64\n",
      "Distribución de y_test:\n",
      "koi_disposition\n",
      "FALSE POSITIVE    726\n",
      "CONFIRMED         412\n",
      "CANDIDATE         297\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribución de y_train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"Distribución de y_test:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "868c7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "def add_false_positives_half(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    X_fp,                      # numpy array de FP (mismas columnas/features)\n",
    "    groups_fp=None,            # opcional: array con kepid u otro ID por fila de X_fp\n",
    "    random_state=42\n",
    "):\n",
    "    n_fp = X_fp.shape[0]\n",
    "    y_fp = np.zeros(n_fp, dtype=int)     # todos los FP son clase 0\n",
    "\n",
    "    # Split 50/50 de FP (ideal: por grupos/estrellas)\n",
    "    if groups_fp is not None:\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=random_state)\n",
    "        idx = np.arange(n_fp)\n",
    "        fp_train_rel, fp_test_rel = next(gss.split(idx, groups=groups_fp))\n",
    "        fp_train_idx, fp_test_idx = idx[fp_train_rel], idx[fp_test_rel]\n",
    "    else:\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        perm = rng.permutation(n_fp)\n",
    "        half = n_fp // 2\n",
    "        fp_train_idx, fp_test_idx = perm[:half], perm[half:]\n",
    "\n",
    "    X_fp_train, y_fp_train = X_fp[fp_train_idx], y_fp[fp_train_idx]\n",
    "    X_fp_test,  y_fp_test  = X_fp[fp_test_idx],  y_fp[fp_test_idx]\n",
    "\n",
    "    # Concatenar a tus splits existentes\n",
    "    X_train_new = np.vstack([X_train, X_fp_train])\n",
    "    y_train_new = np.concatenate([y_train, y_fp_train])\n",
    "    X_test_new  = np.vstack([X_test,  X_fp_test])\n",
    "    y_test_new  = np.concatenate([y_test,  y_fp_test])\n",
    "\n",
    "    return X_train_new, y_train_new, X_test_new, y_test_new, fp_train_idx, fp_test_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df30902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP shape: (4839, 36)\n"
     ]
    }
   ],
   "source": [
    "X_fp = df[df['koi_disposition'] == 'FALSE POSITIVE'].drop(columns=['koi_disposition'] + non_numeric_cols).values\n",
    "print(\"FP shape:\", X_fp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "489153a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6694, 36), (6694,), (1435, 36), (1435,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "defcea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, fp_train_idx, fp_test_idx = add_false_positives_half(\n",
    "    X_train, y_train, X_test, y_test, X_fp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04f4f07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de y_train:\n",
      "FALSE POSITIVE    3387\n",
      "0                 2419\n",
      "CONFIRMED         1922\n",
      "CANDIDATE         1385\n",
      "Name: count, dtype: int64\n",
      "Distribución de y_test:\n",
      "0                 2420\n",
      "FALSE POSITIVE     726\n",
      "CONFIRMED          412\n",
      "CANDIDATE          297\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribución de y_train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"Distribución de y_test:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b871e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "Distribución de y_train:\n",
      "0    7191\n",
      "1    1922\n",
      "Name: count, dtype: int64\n",
      "Distribución de y_test:\n",
      "0    3443\n",
      "1     412\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], shape=(9113,), dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform all Positive or False Positive or Candidate labels to 1 or 0 (y_train and y_test dont have .map method)\n",
    "# if y_train == 'CONFIRMED' or y_train == 1 =1\n",
    "# if y_train == 'CANDIDATE' =0 or y_train == 0 =0\n",
    "# if y_train == 'FALSE POSITIVE' =0 or y_train == 0 =0\n",
    "for index, i in enumerate(y_train):\n",
    "    if i == 'CONFIRMED' or i == 1:\n",
    "        y_train[index] = 1\n",
    "        print(\"ffff\", y_train[index])\n",
    "    elif i == 'CANDIDATE' or i == 0:\n",
    "        y_train[index] = 0\n",
    "    elif i == 'FALSE POSITIVE' or i == 0:\n",
    "        y_train[index] = 0\n",
    "#y_train[3]=1\n",
    "\n",
    "for index, i in enumerate(y_test):\n",
    "    if i == 'CONFIRMED' or i == 1:\n",
    "        y_test[index] = 1\n",
    "        print(\"ffff\", y_test[index])\n",
    "    elif i == 'CANDIDATE' or i == 0:\n",
    "        y_test[index] = 0\n",
    "    elif i == 'FALSE POSITIVE' or i == 0:\n",
    "        y_test[index] = 0\n",
    "#y_train[3]=1\n",
    "\n",
    "#chequear si se cambiaron bien las etiquetas (fijarse cuantos 0 y 1 hay)()\n",
    "print(\"Distribución de y_train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"Distribución de y_test:\")\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbe96b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de y_train:\n",
      "0    7191\n",
      "1    1922\n",
      "Name: count, dtype: int64\n",
      "Distribución de y_test:\n",
      "0    3443\n",
      "1     412\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribución de y_train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"Distribución de y_test:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "138b0242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9113, 36), (9113,), (3855, 36), (3855,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6de6254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=1600, criterion='entropy', random_state=42, n_jobs=-1\n",
    "    )\n",
    "    et = ExtraTreesClassifier(\n",
    "        n_estimators=200, criterion='entropy', random_state=42, n_jobs=-1\n",
    "    )\n",
    "    adb = AdaBoostClassifier(\n",
    "        n_estimators=974, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=1600, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    meta = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    stack = StackingClassifier(\n",
    "        estimators=[('rf', rf), ('gb', gb)],\n",
    "        final_estimator=meta,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        passthrough=False\n",
    "    )\n",
    "    return {\n",
    "        'RandomForest': rf,\n",
    "        'ExtraTrees': et,\n",
    "        'AdaBoost': adb,\n",
    "        'Stacking': stack\n",
    "    }\n",
    "\n",
    "modelos = build_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85b8f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_metrics_at_threshold(y_true, y_proba, subgroup, thr):\n",
    "    y_pred = (y_proba >= thr).astype(int)\n",
    "    # Máscara por subgrupo en test\n",
    "    m_conf = subgroup == 'CONFIRMED'\n",
    "    m_cand = subgroup == 'CANDIDATE'\n",
    "    m_fp   = subgroup == 'FALSE POSITIVE'\n",
    "    \n",
    "    # TPR (recall) en confirmados (true label=1)\n",
    "    tpr_conf = ( (y_pred[m_conf] == 1).sum() / max(1, (y_true[m_conf] == 1).sum()) ) if m_conf.any() else np.nan\n",
    "    \n",
    "    # FPR en FP y en candidates (subgrupos con true label=0)\n",
    "    # (predice 1 cuando la verdad es 0 dentro de cada subgrupo)\n",
    "    def fpr(mask):\n",
    "        if not mask.any(): \n",
    "            return np.nan\n",
    "        tn_fp = (y_true[mask] == 0).sum()\n",
    "        if tn_fp == 0: \n",
    "            return np.nan\n",
    "        return ( (y_pred[mask] == 1).sum() / tn_fp )\n",
    "    \n",
    "    fpr_fp   = fpr(m_fp)\n",
    "    fpr_cand = fpr(m_cand)\n",
    "    \n",
    "    return tpr_conf, fpr_fp, fpr_cand\n",
    "\n",
    "def pick_operating_point(y_true, y_proba, subgroup, max_fpr_fp=0.10, grid=np.linspace(0.01, 0.99, 99)):\n",
    "    # Selecciona el umbral con FPR_FP <= max_fpr_fp que maximiza TPR_confirmed.\n",
    "    # Si ninguno cumple, elige el de menor FPR_FP; si empata, mayor TPR.\n",
    "    best = {'thr': None, 'tpr_conf': -1, 'fpr_fp': 1e9, 'fpr_cand': None}\n",
    "    candidates = []\n",
    "    for thr in grid:\n",
    "        tpr_conf, fpr_fp, fpr_cand = stratified_metrics_at_threshold(y_true, y_proba, subgroup, thr)\n",
    "        candidates.append((thr, tpr_conf, fpr_fp, fpr_cand))\n",
    "    \n",
    "    # Primero, los que cumplen el tope de FPR_FP\n",
    "    valid = [c for c in candidates if np.isfinite(c[2]) and c[2] <= max_fpr_fp]\n",
    "    if valid:\n",
    "        # Maximizá TPR_confirmed; tie-break: menor FPR_FP; luego umbral más alto\n",
    "        valid.sort(key=lambda x: (-(x[1] if x[1] is not None else -1), x[2], -x[0]))\n",
    "        thr, tpr_conf, fpr_fp, fpr_cand = valid[0]\n",
    "    else:\n",
    "        # Ninguno cumple → minimizá FPR_FP; tie-break: mayor TPR\n",
    "        filt = [c for c in candidates if np.isfinite(c[2])]\n",
    "        filt.sort(key=lambda x: (x[2], -(x[1] if x[1] is not None else -1), -x[0]))\n",
    "        thr, tpr_conf, fpr_fp, fpr_cand = filt[0]\n",
    "    \n",
    "    return {\n",
    "        'thr': thr,\n",
    "        'TPR_confirmed': tpr_conf,\n",
    "        'FPR_FP': fpr_fp,\n",
    "        'FPR_candidates': fpr_cand\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71754a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dtype: float64\n",
      "X_test  dtype: float64\n",
      "y_train dtype: object unique: [0 1]\n",
      "y_test  dtype: object unique: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train dtype:\", getattr(X_train, \"dtype\", None))\n",
    "print(\"X_test  dtype:\", getattr(X_test,  \"dtype\", None))\n",
    "print(\"y_train dtype:\", getattr(y_train, \"dtype\", None), \"unique:\", np.unique(y_train))\n",
    "print(\"y_test  dtype:\", getattr(y_test,  \"dtype\", None), \"unique:\", np.unique(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08ef8e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de y_train:\n",
      "0    7191\n",
      "1    1922\n",
      "Name: count, dtype: int64\n",
      "Distribución de y_test:\n",
      "0    3443\n",
      "1     412\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribución de y_train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"Distribución de y_test:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8e68b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train tiene NaNs? False\n",
      "y_test tiene NaNs? False\n"
     ]
    }
   ],
   "source": [
    "#chequear si hay nans en y_train o y_test\n",
    "print(\"y_train tiene NaNs?\", pd.isnull(y_train).any())\n",
    "print(\"y_test tiene NaNs?\", pd.isnull(y_test).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bf0acfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: type=<class 'numpy.ndarray'>, shape=(9113,), np.dtype=object, sk_type=unknown\n",
      "y_test: type=<class 'numpy.ndarray'>, shape=(3855,), np.dtype=object, sk_type=unknown\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def diag_y(y, name):\n",
    "    a = np.asarray(y)\n",
    "    print(f\"{name}: type={type(y)}, shape={a.shape}, np.dtype={a.dtype}, sk_type={type_of_target(a)}\")\n",
    "\n",
    "diag_y(y_train, \"y_train\")\n",
    "diag_y(y_test,  \"y_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27aed6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train sk_type: binary   uniques: [0 1]\n",
      "y_test  sk_type: binary   uniques: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Forzar 1D + int64 \"duro\" en y\n",
    "y_train = pd.Series(y_train).astype(\"int64\").to_numpy().ravel()\n",
    "y_test  = pd.Series(y_test ).astype(\"int64\").to_numpy().ravel()\n",
    "\n",
    "# (Opcional pero recomendable) asegurar X como float NumPy 2D\n",
    "X_train = np.asarray(X_train, dtype=float)\n",
    "X_test  = np.asarray(X_test,  dtype=float)\n",
    "\n",
    "# Chequeo post-fix\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "print(\"y_train sk_type:\", type_of_target(y_train), \"  uniques:\", np.unique(y_train))\n",
    "print(\"y_test  sk_type:\", type_of_target(y_test),  \"  uniques:\", np.unique(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "277aa8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Entrenando RandomForest_fp ===\n",
      "y_train distrib: {0: 7191, 1: 1922}\n",
      "RandomForest_fp classes_ aprendidas: [0 1]\n",
      "Guardado: models\\fps\\experimento\\RandomForest_fp.pkl\n",
      "Umbral elegido: 0.383 | PR-AUC=0.9250 | ROC-AUC=0.9906\n",
      "[0.5]     Acc=0.968 Prec=0.880 Rec=0.816 F1=0.846  CM=[[3397, 46], [76, 336]]\n",
      "[@thr]    Acc=0.970 Prec=0.836 Rec=0.891 F1=0.863 CM=[[3371, 72], [45, 367]]\n",
      "\n",
      "=== Entrenando ExtraTrees_fp ===\n",
      "y_train distrib: {0: 7191, 1: 1922}\n",
      "ExtraTrees_fp classes_ aprendidas: [0 1]\n",
      "Guardado: models\\fps\\experimento\\ExtraTrees_fp.pkl\n",
      "Umbral elegido: 0.375 | PR-AUC=0.9213 | ROC-AUC=0.9902\n",
      "[0.5]     Acc=0.969 Prec=0.869 Rec=0.835 F1=0.851  CM=[[3391, 52], [68, 344]]\n",
      "[@thr]    Acc=0.968 Prec=0.813 Rec=0.905 F1=0.856 CM=[[3357, 86], [39, 373]]\n",
      "\n",
      "=== Entrenando AdaBoost_fp ===\n",
      "y_train distrib: {0: 7191, 1: 1922}\n",
      "AdaBoost_fp classes_ aprendidas: [0 1]\n",
      "Guardado: models\\fps\\experimento\\AdaBoost_fp.pkl\n",
      "Umbral elegido: 0.479 | PR-AUC=0.8788 | ROC-AUC=0.9851\n",
      "[0.5]     Acc=0.963 Prec=0.864 Rec=0.772 F1=0.815  CM=[[3393, 50], [94, 318]]\n",
      "[@thr]    Acc=0.963 Prec=0.804 Rec=0.869 F1=0.835 CM=[[3356, 87], [54, 358]]\n",
      "\n",
      "=== Entrenando Stacking_fp ===\n",
      "y_train distrib: {0: 7191, 1: 1922}\n",
      "Stacking_fp classes_ aprendidas: [0 1]\n",
      "Guardado: models\\fps\\experimento\\Stacking_fp.pkl\n",
      "Umbral elegido: 0.286 | PR-AUC=0.9301 | ROC-AUC=0.9914\n",
      "[0.5]     Acc=0.971 Prec=0.895 Rec=0.828 F1=0.860  CM=[[3403, 40], [71, 341]]\n",
      "[@thr]    Acc=0.972 Prec=0.861 Rec=0.883 F1=0.872 CM=[[3384, 59], [48, 364]]\n",
      "\n",
      "Resumen por modelo:\n",
      "           model  PR_AUC  ROC_AUC  thr*  Acc@0.5  F1@0.5  Acc@thr  F1@thr\n",
      "    Stacking_fp  0.9301   0.9914 0.286   0.9712  0.8600   0.9722  0.8719\n",
      "RandomForest_fp  0.9250   0.9906 0.383   0.9684  0.8463   0.9696  0.8625\n",
      "  ExtraTrees_fp  0.9213   0.9902 0.375   0.9689  0.8515   0.9676  0.8565\n",
      "    AdaBoost_fp  0.8788   0.9851 0.479   0.9626  0.8154   0.9634  0.8355\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json, os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix,\n",
    "    precision_recall_curve, classification_report\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "MODELS_DIR = Path(\"models/fps/experimento\")\n",
    "MODELS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "\n",
    "def build_subgroup_table(y_true, y_pred, subgroup):\n",
    "    \"\"\"Devuelve una tabla con TP, TN, FP, FN y tasas por subgrupo del test.\"\"\"\n",
    "    rows = []\n",
    "    subcats = pd.Series(subgroup).astype(str).unique().tolist()\n",
    "    for sg in subcats:\n",
    "        m = (subgroup == sg)\n",
    "        yt = y_true[m]\n",
    "        yp = y_pred[m]\n",
    "        n = int(m.sum())\n",
    "        if n == 0:\n",
    "            continue\n",
    "        P = int((yt == 1).sum())\n",
    "        N = int((yt == 0).sum())\n",
    "        TP = int(((yt == 1) & (yp == 1)).sum())\n",
    "        FN = int(((yt == 1) & (yp == 0)).sum())\n",
    "        FP = int(((yt == 0) & (yp == 1)).sum())\n",
    "        TN = int(((yt == 0) & (yp == 0)).sum())\n",
    "        tpr = TP / (TP + FN) if (TP + FN) > 0 else np.nan      # recall (si hay positivos)\n",
    "        fpr = FP / (FP + TN) if (FP + TN) > 0 else np.nan      # tasa de falsos positivos (si hay negativos)\n",
    "        tnr = TN / (TN + FP) if (TN + FP) > 0 else np.nan\n",
    "        fnr = FN / (FN + TP) if (FN + TP) > 0 else np.nan\n",
    "        acc_sg = (TP + TN) / n if n > 0 else np.nan\n",
    "        ppr = (TP + FP) / n  # predicted positive rate\n",
    "        rows.append({\n",
    "            \"subgroup\": sg,\n",
    "            \"N\": n,\n",
    "            \"P(true=1)\": P,\n",
    "            \"N(true=0)\": N,\n",
    "            \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
    "            \"Accuracy_sg\": round(float(acc_sg), 4),\n",
    "            \"TPR_recall\": round(float(tpr), 4) if np.isfinite(tpr) else None,\n",
    "            \"FPR\": round(float(fpr), 4) if np.isfinite(fpr) else None,\n",
    "            \"TNR\": round(float(tnr), 4) if np.isfinite(tnr) else None,\n",
    "            \"FNR\": round(float(fnr), 4) if np.isfinite(fnr) else None,\n",
    "            \"PredPosRate\": round(float(ppr), 4),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def safe_proba(clf, X, pos_label=1):\n",
    "    import numpy as np\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        proba = clf.predict_proba(X)\n",
    "        classes = getattr(clf, \"classes_\", None)\n",
    "        if proba.ndim == 2 and classes is not None:\n",
    "            if proba.shape[1] == 2:\n",
    "                j = int(np.where(classes == pos_label)[0][0])\n",
    "                return proba[:, j]\n",
    "            if proba.shape[1] == 1:\n",
    "                learned = classes[0] if classes is not None and len(classes)==1 else None\n",
    "                return np.full(X.shape[0], 1.0 if learned == pos_label else 0.0, dtype=float)\n",
    "        return proba.ravel().astype(float)\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        z = clf.decision_function(X)\n",
    "        z = (z - z.min()) / (z.max() - z.min() + 1e-9)\n",
    "        return z.astype(float)\n",
    "    return clf.predict(X).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "def f1_from_pr(prec, rec):\n",
    "    denom = (prec + rec)\n",
    "    denom[denom == 0] = 1e-9\n",
    "    return 2 * prec * rec / denom\n",
    "\n",
    "def choose_threshold_max_f1(y_true, y_proba):\n",
    "    prec, rec, thr = precision_recall_curve(y_true, y_proba)\n",
    "    f1 = f1_from_pr(prec[:-1], rec[:-1])  # descarta último punto (sin threshold)\n",
    "    i = np.argmax(f1)\n",
    "    return float(thr[i])\n",
    "\n",
    "def stratified_metrics_at_thr(y_true, y_proba, subgroup, thr):\n",
    "    y_pred = (y_proba >= thr).astype(int)\n",
    "    # Masks\n",
    "    m_conf = subgroup == 'CONFIRMED'\n",
    "    m_cand = subgroup == 'CANDIDATE'\n",
    "    m_fp   = subgroup == 'FALSE POSITIVE'\n",
    "    # TPR en confirmados (clase 1)\n",
    "    tpr_conf = np.nan\n",
    "    if m_conf.any():\n",
    "        denom = max(1, (y_true[m_conf] == 1).sum())\n",
    "        tpr_conf = ( (y_pred[m_conf] == 1).sum() / denom )\n",
    "    # FPR en FP y CAND (casos true=0 pred=1)\n",
    "    def fpr(mask):\n",
    "        if not mask.any(): return np.nan\n",
    "        neg = (y_true[mask] == 0).sum()\n",
    "        if neg == 0: return np.nan\n",
    "        return ( (y_pred[mask] == 1).sum() / neg )\n",
    "    return float(tpr_conf), float(fpr(m_fp)), float(fpr(m_cand))\n",
    "\n",
    "def choose_threshold_with_fp_cap(y_true, y_proba, subgroup, max_fpr_fp=0.10):\n",
    "    grid = np.linspace(0.01, 0.99, 99)\n",
    "    candidates = []\n",
    "    for thr in grid:\n",
    "        tpr_c, fpr_fp, fpr_cand = stratified_metrics_at_thr(y_true, y_proba, subgroup, thr)\n",
    "        candidates.append((thr, tpr_c, fpr_fp, fpr_cand))\n",
    "    # primero los que cumplen el cap\n",
    "    valid = [c for c in candidates if np.isfinite(c[2]) and c[2] <= max_fpr_fp]\n",
    "    if valid:\n",
    "        # max TPR_conf, tie-break: menor FPR_FP, luego thr más alto\n",
    "        valid.sort(key=lambda x: (-(x[1] if np.isfinite(x[1]) else -1), x[2], -x[0]))\n",
    "        return {\n",
    "            'thr': float(valid[0][0]),\n",
    "            'TPR_confirmed': float(valid[0][1]),\n",
    "            'FPR_FP': float(valid[0][2]),\n",
    "            'FPR_candidates': float(valid[0][3]),\n",
    "        }\n",
    "    # si ninguno cumple, minimizá FPR_FP; tie-break: mayor TPR_conf\n",
    "    candidates = [c for c in candidates if np.isfinite(c[2])]\n",
    "    candidates.sort(key=lambda x: (x[2], -(x[1] if np.isfinite(x[1]) else -1), -x[0]))\n",
    "    best = candidates[0]\n",
    "    return {\n",
    "        'thr': float(best[0]),\n",
    "        'TPR_confirmed': float(best[1]),\n",
    "        'FPR_FP': float(best[2]),\n",
    "        'FPR_candidates': float(best[3]),\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# Construcción de modelos\n",
    "# =========================\n",
    "def build_models():\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=1600, criterion='entropy', random_state=RANDOM_STATE, n_jobs=-1\n",
    "    )\n",
    "    et = ExtraTreesClassifier(\n",
    "        n_estimators=200, criterion='entropy', random_state=RANDOM_STATE, n_jobs=-1\n",
    "    )\n",
    "    adb = AdaBoostClassifier(\n",
    "        n_estimators=1000, learning_rate=0.05, random_state=RANDOM_STATE\n",
    "    )\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=1800, learning_rate=0.05, random_state=RANDOM_STATE\n",
    "    )\n",
    "    meta = LogisticRegression(max_iter=900, random_state=RANDOM_STATE)\n",
    "    stack = StackingClassifier(\n",
    "        estimators=[('rf', rf), ('gb', gb)],\n",
    "        final_estimator=meta,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        passthrough=False\n",
    "    )\n",
    "    return {\n",
    "        \"RandomForest_fp\": rf,\n",
    "        \"ExtraTrees_fp\": et,\n",
    "        \"AdaBoost_fp\": adb,\n",
    "        \"Stacking_fp\": stack\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# Entrenar, guardar, evaluar\n",
    "# =========================\n",
    "def train_save_eval_all(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    subgroup_test=None,    # np.array(['CONFIRMED','CANDIDATE','FALSE POSITIVE',...])\n",
    "    max_fpr_fp=0.10\n",
    "):\n",
    "    models = build_models()\n",
    "    rows_summary = []\n",
    "    all_subgroups = []  # para juntar tablas de todos los modelos\n",
    "\n",
    "    for name, clf in models.items():\n",
    "        print(f\"\\n=== Entrenando {name} ===\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        # Dentro de train_save_eval_all(), justo después de clf.fit(X_train, y_train):\n",
    "        unique, counts = np.unique(y_train, return_counts=True)\n",
    "        print(f\"y_train distrib: {dict(zip(unique.tolist(), counts.tolist()))}\")\n",
    "\n",
    "        classes = getattr(clf, \"classes_\", None)\n",
    "        print(f\"{name} classes_ aprendidas: {classes}\")\n",
    "\n",
    "        if classes is not None and len(classes) < 2:\n",
    "            print(f\"⚠️  Aviso: {name} se entrenó con UNA sola clase ({classes[0]}). \"\n",
    "                f\"Revisá tu split: asegurá que y_train tenga 0s y 1s.\")\n",
    "\n",
    "        # Guardar modelo\n",
    "        model_path = MODELS_DIR / f\"{name}.pkl\"\n",
    "        joblib.dump(clf, model_path)\n",
    "        print(f\"Guardado: {model_path}\")\n",
    "\n",
    "        # Probabilidades\n",
    "        y_proba = safe_proba(clf, X_test)\n",
    "\n",
    "        # Métricas globales @0.5\n",
    "        y_pred05 = (y_proba >= 0.5).astype(int)\n",
    "        acc = accuracy_score(y_test, y_pred05)\n",
    "        prec = precision_score(y_test, y_pred05, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred05, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred05, zero_division=0)\n",
    "        cm = confusion_matrix(y_test, y_pred05)\n",
    "        try:\n",
    "            roc = roc_auc_score(y_test, y_proba)\n",
    "        except:\n",
    "            roc = np.nan\n",
    "        ap = average_precision_score(y_test, y_proba)\n",
    "\n",
    "        # Elegir umbral operativo\n",
    "        meta_thr = {}\n",
    "        if subgroup_test is not None:\n",
    "            meta_thr = choose_threshold_with_fp_cap(y_test, y_proba, subgroup_test, max_fpr_fp=max_fpr_fp)\n",
    "            thr = meta_thr['thr']\n",
    "        else:\n",
    "            thr = choose_threshold_max_f1(y_test, y_proba)\n",
    "            meta_thr = {\"thr\": thr}\n",
    "\n",
    "        # Métricas al umbral elegido\n",
    "        y_pred_thr = (y_proba >= thr).astype(int)\n",
    "        acc_thr = accuracy_score(y_test, y_pred_thr)\n",
    "        prec_thr = precision_score(y_test, y_pred_thr, zero_division=0)\n",
    "        rec_thr = recall_score(y_test, y_pred_thr, zero_division=0)\n",
    "        f1_thr = f1_score(y_test, y_pred_thr, zero_division=0)\n",
    "        cm_thr = confusion_matrix(y_test, y_pred_thr)\n",
    "\n",
    "        # Report corto\n",
    "        print(f\"Umbral elegido: {thr:.3f} | PR-AUC={ap:.4f} | ROC-AUC={roc:.4f}\")\n",
    "        print(f\"[0.5]     Acc={acc:.3f} Prec={prec:.3f} Rec={rec:.3f} F1={f1:.3f}  CM={cm.tolist()}\")\n",
    "        print(f\"[@thr]    Acc={acc_thr:.3f} Prec={prec_thr:.3f} Rec={rec_thr:.3f} F1={f1_thr:.3f} CM={cm_thr.tolist()}\")\n",
    "        if subgroup_test is not None:\n",
    "            print(f\"          TPR_confirmed={meta_thr['TPR_confirmed']:.3f}  FPR_FP={meta_thr['FPR_FP']:.3f}  FPR_candidates={meta_thr['FPR_candidates']:.3f}\")\n",
    "\n",
    "        # Guardar metadatos (umbral y métricas)\n",
    "        meta_to_save = {\n",
    "            \"threshold\": float(thr),\n",
    "            \"PR_AUC\": float(ap),\n",
    "            \"ROC_AUC\": float(roc) if roc==roc else None,\n",
    "            \"metrics@0.5\": {\n",
    "                \"accuracy\": float(acc), \"precision\": float(prec),\n",
    "                \"recall\": float(rec), \"f1\": float(f1),\n",
    "                \"confusion_matrix\": cm.tolist()\n",
    "            },\n",
    "            \"metrics@thr\": {\n",
    "                \"accuracy\": float(acc_thr), \"precision\": float(prec_thr),\n",
    "                \"recall\": float(rec_thr), \"f1\": float(f1_thr),\n",
    "                \"confusion_matrix\": cm_thr.tolist()\n",
    "            }\n",
    "        }\n",
    "        # añade TPR/FPR si existen\n",
    "        for k in (\"TPR_confirmed\",\"FPR_FP\",\"FPR_candidates\"):\n",
    "            if k in meta_thr:\n",
    "                meta_to_save[k] = float(meta_thr[k])\n",
    "\n",
    "        with open(MODELS_DIR / f\"{name}_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(meta_to_save, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        # --- NUEVO: tabla estratificada por subgrupo @thr ---\n",
    "        if subgroup_test is not None:\n",
    "            df_sg = build_subgroup_table(y_test, y_pred_thr, subgroup_test)\n",
    "            df_sg.insert(0, \"model\", name)\n",
    "            all_subgroups.append(df_sg)\n",
    "            # guardar CSV por modelo\n",
    "            csv_path = MODELS_DIR / f\"{name}_subgroup_eval.csv\"\n",
    "            df_sg.to_csv(csv_path, index=False)\n",
    "            print(f\"Tabla por subgrupo guardada en: {csv_path}\")\n",
    "\n",
    "        # Para tabla resumen\n",
    "        row = {\n",
    "            \"model\": name,\n",
    "            \"PR_AUC\": round(float(ap), 4),\n",
    "            \"ROC_AUC\": round(float(roc), 4) if roc==roc else None,\n",
    "            \"thr*\": round(float(thr), 3),\n",
    "            \"Acc@0.5\": round(float(acc), 4),\n",
    "            \"F1@0.5\": round(float(f1), 4),\n",
    "            \"Acc@thr\": round(float(acc_thr), 4),\n",
    "            \"F1@thr\": round(float(f1_thr), 4),\n",
    "        }\n",
    "        if subgroup_test is not None:\n",
    "            row.update({\n",
    "                \"TPR_confirmed@thr\": round(float(meta_thr['TPR_confirmed']), 4),\n",
    "                \"FPR_FP@thr\": round(float(meta_thr['FPR_FP']), 4),\n",
    "                \"FPR_cand@thr\": round(float(meta_thr['FPR_candidates']), 4),\n",
    "            })\n",
    "        rows_summary.append(row)\n",
    "\n",
    "    results = pd.DataFrame(rows_summary).sort_values([\"F1@thr\",\"PR_AUC\"], ascending=False)\n",
    "    results_by_subgroup = pd.concat(all_subgroups, ignore_index=True) if all_subgroups else pd.DataFrame()\n",
    "    # También guardamos la tabla completa por subgrupo\n",
    "    if not results_by_subgroup.empty:\n",
    "        results_by_subgroup.to_csv(MODELS_DIR / \"ALL_MODELS_subgroup_eval.csv\", index=False)\n",
    "    return results, results_by_subgroup\n",
    "\n",
    "# =========================\n",
    "# USO: reemplazá con tus arrays\n",
    "# =========================\n",
    "# X_train, y_train, X_test, y_test = ...  # ya los tenés\n",
    "# subgroup_test = None  # o np.array([...]) con etiquetas 'CONFIRMED'/'CANDIDATE'/'FALSE POSITIVE'\n",
    "\n",
    "\n",
    "results, results_by_subgroup = train_save_eval_all(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    subgroup_test=None,   # si no lo tenés, poné None y la tabla estratificada no se genera\n",
    "    max_fpr_fp=0.10                # ajustá el tope de FPR sobre FP\n",
    ")\n",
    "\n",
    "print(\"\\nResumen por modelo:\\n\", results.to_string(index=False))\n",
    "if not results_by_subgroup.empty:\n",
    "    print(\"\\nMétricas por subgrupo (primeras filas):\\n\", results_by_subgroup.head().to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eea675a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo cargado en test: 0.0000\n"
     ]
    }
   ],
   "source": [
    "test_model = joblib.load(MODELS_DIR / \"Stacking_fp.pkl\")\n",
    "acc = test_model.score(X_test, y_test)\n",
    "print(f\"Precisión del modelo cargado en test: {acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3c4d12bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.21697268,  11.660292  , -11.660292  , ...,  -1.00898056,\n",
       "          0.31542842,   0.82896309],\n",
       "       [ -0.05437479,  -0.25119181,   0.25119181, ...,  -1.09957289,\n",
       "         -1.6526893 ,   1.15885417],\n",
       "       [ -0.05599268,  -0.25430723,   0.25430723, ...,   0.73623094,\n",
       "         -1.4119126 ,   0.46153517],\n",
       "       ...,\n",
       "       [ -0.0564667 ,  -0.25424885,   0.25424885, ...,  -0.46873306,\n",
       "         -0.02366032,   0.69614043],\n",
       "       [ -0.05428406,  -0.25365113,   0.25365113, ...,  -0.08836486,\n",
       "         -0.38158604,   0.96322949],\n",
       "       [ -0.04836495,  -0.25288982,   0.25288982, ...,  -0.83764609,\n",
       "         -0.40406585,  -0.52597248]], shape=(6694, 36))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a0eb8e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05625144, -0.25409284,  0.25409284, ...,  1.49845063,\n",
       "         0.09200553, -1.96103477],\n",
       "       [-0.05627182, -0.2538977 ,  0.2538977 , ...,  0.18014132,\n",
       "        -0.26668608, -0.92588421],\n",
       "       [-0.05616862, -0.25421059,  0.25421059, ..., -0.83337033,\n",
       "        -0.16724576,  0.66943152],\n",
       "       ...,\n",
       "       [-0.05225257, -0.25367386,  0.25367386, ..., -0.74780485,\n",
       "         2.0192716 , -0.00478789],\n",
       "       [-0.0059784 , -0.24686046,  0.24686046, ...,  0.29654763,\n",
       "         0.87751213, -2.57317402],\n",
       "       [-0.05542026, -0.25346494,  0.25346494, ...,  0.21629852,\n",
       "        -1.51575968,  0.72862423]], shape=(1435, 36))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc414c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 1 1 1 0 1]\n",
      "[[-0.04958762 -0.25089122  0.25089122  0.06413124 -0.33209748  0.33209748\n",
      "  -0.17705896 -0.16930091  0.14802713 -0.41168563 -0.37958252  0.37958252\n",
      "  -0.27589595 -0.02462454  0.02462454 -0.03207393 -0.04365383  0.02702136\n",
      "  -0.33837288 -0.04726239 -0.06648603  0.0447978  -0.2751294  -0.35908646\n",
      "  -0.32509857 -1.39770158  1.14484617  0.35762874 -0.41734618  0.55645492\n",
      "  -0.12877136 -0.27734027  0.15124239 -0.02642094  1.20276381  0.78132018]\n",
      " [-0.01592372 -0.22354545  0.22354545 -0.05402914 -0.27185396  0.27185396\n",
      "  -0.04310476 -0.19744549 -0.09540984 -0.17224066 -0.32752538  0.32752538\n",
      "  -0.27268994 -0.02063815  0.02063815 -0.0318851  -0.04349743  0.02698718\n",
      "  -0.75462758 -0.04780217 -0.06697722  0.04497078 -0.28791995  1.16998874\n",
      "  -0.32509857 -1.39770158  1.14484617  0.35762874 -0.41734618  0.55645492\n",
      "  -0.12877136 -0.27734027  0.15124239 -0.02642094  1.20276381  0.78132018]\n",
      " [-0.04178714 -0.2524824   0.2524824   0.14233885 -0.40204198  0.40204198\n",
      "   0.07349628  0.35316692  0.2045832  -0.5933053  -0.45255412  0.45255412\n",
      "  -0.14947301  0.0131216  -0.0131216  -0.02798589 -0.03411356  0.02603041\n",
      "  -0.52271425 -0.04760928 -0.06645665  0.04486869 -0.22332768 -0.35908646\n",
      "   0.18409279  0.27761028 -0.19538167  0.53880652 -0.57119199 -0.40256458\n",
      "  -0.13858659 -0.13638305  0.14320559  1.03739693  1.20067497  0.84556593]\n",
      " [-0.05539509 -0.25430549  0.25430549  0.06072722 -0.42268424  0.42268424\n",
      "   0.16695978 -0.19136018  0.1922884  -0.49684583 -0.49641341  0.49641341\n",
      "  -0.1835111  -0.02629384  0.02629384 -0.02173789 -0.0221752   0.02473194\n",
      "   0.37758519 -0.04216124 -0.05466832  0.04233839  0.32577053 -0.35908646\n",
      "   0.12268278  0.25585298 -0.16716635  0.58586569 -0.50196138 -0.30666263\n",
      "  -0.15139629 -0.17162235  0.14840587 -1.36907144  1.24262963  0.96178576]\n",
      " [-0.05480421 -0.25387099  0.25387099  0.07969177 -0.37772309  0.37772309\n",
      "  -0.00809401 -0.17832021 -0.1240977  -0.61303884 -0.44049396  0.44049396\n",
      "  -0.27605068 -0.02527233  0.02527233 -0.0319116  -0.04203772  0.0268505\n",
      "   0.39066748 -0.04194272 -0.05087298  0.04137292 -0.26860622 -0.35908646\n",
      "   0.4118216   0.51694054 -0.68914982  0.28939295 -0.37119244 -0.81014786\n",
      "  -0.10897455 -0.02515899  0.11720417 -0.69345365  1.22624276  0.89826188]\n",
      " [-0.04838412 -0.25180916  0.25180916  0.07388469 -0.36532001  0.36532001\n",
      "  -0.05771795 -0.20059682 -0.08311504 -0.15871924 -0.41148852  0.41148852\n",
      "  -0.26473435 -0.02345354  0.02345354 -0.03153062 -0.04102113  0.02679071\n",
      "  -0.28842232 -0.04712681 -0.06494483  0.04456705 -0.23586242 -0.35908646\n",
      "   0.43101223  0.95208648 -0.98541071  0.40233495 -0.49426909 -1.03791499\n",
      "  -0.12128517 -0.04608233  0.13044125  0.88661463  1.22581789  1.04624365]\n",
      " [-0.05359879 -0.25303888  0.25303888  0.10006741 -0.34361462  0.34361462\n",
      "   0.01047692 -0.18875218 -0.16835897 -0.38345291 -0.40187092  0.40187092\n",
      "  -0.27502698 -0.02482386  0.02482386 -0.03190497 -0.04198559  0.02689322\n",
      "   0.09809989 -0.04512793 -0.05926272  0.04341618 -0.26950156  1.16998874\n",
      "   0.43101223  0.95208648 -0.98541071  0.40233495 -0.49426909 -1.03791499\n",
      "  -0.12128517 -0.04608233  0.13044125  0.88661463  1.22581789  1.04624365]\n",
      " [-0.05477349 -0.25212591  0.25212591  0.19687902 -0.22357055  0.22357055\n",
      "   0.00834583 -0.18081954 -0.16098209 -0.49335499 -0.25272186  0.25272186\n",
      "  -0.28071485 -0.02529724  0.02529724 -0.03229589 -0.04297611  0.02700427\n",
      "   0.33595972 -0.04269936 -0.05235911  0.04201787 -0.30173374  2.69906393\n",
      "   0.43101223  0.95208648 -0.98541071  0.40233495 -0.49426909 -1.03791499\n",
      "  -0.12128517 -0.04608233  0.13044125  0.88661463  1.22581789  1.04624365]\n",
      " [-0.0511807  -0.25169488  0.25169488 -0.49963214 -0.3157077   0.3157077\n",
      "   0.13438455  0.57126029  0.23163175 -0.09265746 -0.29699333  0.29699333\n",
      "  -0.28062573 -0.02803789  0.02803789 -0.01983301 -0.02751879  0.0188888\n",
      "   0.31455233 -0.04295826 -0.0605757   0.0407831  -0.25990865 -0.35908646\n",
      "   0.66257915 -0.74498267  0.53821673 -0.77414417  0.49034412  0.53247943\n",
      "   0.04274558 -0.03837373 -0.04825942  1.4275293  -0.46066066 -1.15832387]\n",
      " [-0.04465712 -0.25298671  0.25298671  0.1095287  -0.40487697  0.40487697\n",
      "  -0.20567645 -0.17538622  0.22507452 -0.32249064 -0.46782015  0.46782015\n",
      "  -0.22268745 -0.02118628  0.02118628 -0.03091444 -0.0437581   0.02673091\n",
      "  -0.56790762 -0.04766391 -0.06694784  0.04491277 -0.1138406  -0.35908646\n",
      "  -0.8675537  -1.52824536  1.11663085  0.39998199 -0.27119266  1.37162149\n",
      "  -0.14191378 -0.35662871  0.14604211 -1.06173937  1.26778337  1.13792017]]\n",
      "[1 1 0 0 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "download_model = joblib.load(MODELS_DIR / \"Stacking_fp.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "first10= df.head(10).drop(columns=['koi_disposition',] + non_numeric_cols)\n",
    "first10_scaled = scaler.transform(first10)\n",
    "y=download_model.predict(first10_scaled)\n",
    "print(y)\n",
    "\n",
    "print(X_scaled[:10])  # primeras 10 filas de X escalado\n",
    "print(download_model.predict(X_scaled[:10]))  # primeras 10 predicciones en el test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
