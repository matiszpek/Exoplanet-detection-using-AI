{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42f1272c",
   "metadata": {},
   "source": [
    "# Exoplanet detection using AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a2e58f",
   "metadata": {},
   "source": [
    "This notebook will explore datasets related to exoplanet detection, specifically the Kepler and TESS missions. We will use Python libraries such as Pandas, NumPy, Matplotlib, and Scikit-learn to analyze the data and build a machine learning model to classify potential exoplanets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e06ae8e",
   "metadata": {},
   "source": [
    "Mas especificamente este notebook es el \"hijo\" de un notebook anterior que se llama \"model.ipynb\" y que contiene el modelo inicial donde se hacen un monton de proceso, pruebas y concluciones pero que fueron todas haciendo la postura de no tomar los false positive, sino que se trataba de un modelo binario (planet, no planet). En este notebook se va a tratar de hacer un modelo que tome en cuenta los false positive y que pueda distinguir entre planetas, false positive y no planetas o la ampliacion del modelo de model.ipnynb a un modelo que pueda reconocer de forma inferida los false positive siendo que pueda reentrenarse con las mismas categorias de salida (planet o no planet) pero esta vez tomando las false positive como no planet y se muestren cierta cantidad den el train y otra en el test pudiendo ser que se muestren el 50% en el train y el restante en el test y ver si de esa forma se encuentra la fina distincion que suponemos se puede lograr entre los false positive y los positive. Creemos que va a ser dificil realizar la distincion ya que haciendo la prueba de este modelo viejo probandolo con todos los datos nos dio que la mayoria de los 1 eran positives pero ademas estaban sumados la mayoria de los false positive, y los 0 eran no planetas, pero no se podia distinguir entre false positive y positive.\n",
    "\n",
    "La idea es que este modelo pueda ser reentrenado con los datos de salida de los modelos anteriores y que pueda ir aprendiendo a distinguir entre false positive y positive, pero que en un principio se entrene con los datos originales pero tomando los false positive como no planetas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4797e2f4",
   "metadata": {},
   "source": [
    "*Exploring the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b04d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas numpy matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c18aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3bf24b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kepid</th>\n",
       "      <th>kepoi_name</th>\n",
       "      <th>kepler_name</th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_pdisposition</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.01</td>\n",
       "      <td>Kepler-227 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.02</td>\n",
       "      <td>Kepler-227 c</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10811496</td>\n",
       "      <td>K00753.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10848459</td>\n",
       "      <td>K00754.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10854555</td>\n",
       "      <td>K00755.01</td>\n",
       "      <td>Kepler-664 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      kepid kepoi_name   kepler_name koi_disposition koi_pdisposition  \\\n",
       "0  10797460  K00752.01  Kepler-227 b       CONFIRMED        CANDIDATE   \n",
       "1  10797460  K00752.02  Kepler-227 c       CONFIRMED        CANDIDATE   \n",
       "2  10811496  K00753.01           NaN       CANDIDATE        CANDIDATE   \n",
       "3  10848459  K00754.01           NaN  FALSE POSITIVE   FALSE POSITIVE   \n",
       "4  10854555  K00755.01  Kepler-664 b       CONFIRMED        CANDIDATE   \n",
       "\n",
       "   koi_score  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  ...  \\\n",
       "0      1.000              0              0              0              0  ...   \n",
       "1      0.969              0              0              0              0  ...   \n",
       "2      0.000              0              0              0              0  ...   \n",
       "3      0.000              0              1              0              0  ...   \n",
       "4      1.000              0              0              0              0  ...   \n",
       "\n",
       "   koi_steff_err2  koi_slogg  koi_slogg_err1  koi_slogg_err2  koi_srad  \\\n",
       "0           -81.0      4.467           0.064          -0.096     0.927   \n",
       "1           -81.0      4.467           0.064          -0.096     0.927   \n",
       "2          -176.0      4.544           0.044          -0.176     0.868   \n",
       "3          -174.0      4.564           0.053          -0.168     0.791   \n",
       "4          -211.0      4.438           0.070          -0.210     1.046   \n",
       "\n",
       "   koi_srad_err1  koi_srad_err2         ra        dec  koi_kepmag  \n",
       "0          0.105         -0.061  291.93423  48.141651      15.347  \n",
       "1          0.105         -0.061  291.93423  48.141651      15.347  \n",
       "2          0.233         -0.078  297.00482  48.134129      15.436  \n",
       "3          0.201         -0.067  285.53461  48.285210      15.597  \n",
       "4          0.334         -0.133  288.75488  48.226200      15.509  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "#path = r\"C:\\Users\\matir\\OneDrive\\Documentos\\NASA\\Exoplanet detection using AI\\data\\cumulative_2025.10.04_05.21.55.csv\"\n",
    "path = \"data/cumulative_2025.10.04_05.21.55.csv\"\n",
    "df = pd.read_csv(\n",
    "    path,\n",
    "    comment='#',      # ignore metadata lines starting with '#'\n",
    "    engine='python',  # more forgiving parser\n",
    ")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b641103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9564 entries, 0 to 9563\n",
      "Data columns (total 49 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   kepid              9564 non-null   int64  \n",
      " 1   kepoi_name         9564 non-null   object \n",
      " 2   kepler_name        2747 non-null   object \n",
      " 3   koi_disposition    9564 non-null   object \n",
      " 4   koi_pdisposition   9564 non-null   object \n",
      " 5   koi_score          8054 non-null   float64\n",
      " 6   koi_fpflag_nt      9564 non-null   int64  \n",
      " 7   koi_fpflag_ss      9564 non-null   int64  \n",
      " 8   koi_fpflag_co      9564 non-null   int64  \n",
      " 9   koi_fpflag_ec      9564 non-null   int64  \n",
      " 10  koi_period         9564 non-null   float64\n",
      " 11  koi_period_err1    9110 non-null   float64\n",
      " 12  koi_period_err2    9110 non-null   float64\n",
      " 13  koi_time0bk        9564 non-null   float64\n",
      " 14  koi_time0bk_err1   9110 non-null   float64\n",
      " 15  koi_time0bk_err2   9110 non-null   float64\n",
      " 16  koi_impact         9201 non-null   float64\n",
      " 17  koi_impact_err1    9110 non-null   float64\n",
      " 18  koi_impact_err2    9110 non-null   float64\n",
      " 19  koi_duration       9564 non-null   float64\n",
      " 20  koi_duration_err1  9110 non-null   float64\n",
      " 21  koi_duration_err2  9110 non-null   float64\n",
      " 22  koi_depth          9201 non-null   float64\n",
      " 23  koi_depth_err1     9110 non-null   float64\n",
      " 24  koi_depth_err2     9110 non-null   float64\n",
      " 25  koi_prad           9201 non-null   float64\n",
      " 26  koi_prad_err1      9201 non-null   float64\n",
      " 27  koi_prad_err2      9201 non-null   float64\n",
      " 28  koi_teq            9201 non-null   float64\n",
      " 29  koi_teq_err1       0 non-null      float64\n",
      " 30  koi_teq_err2       0 non-null      float64\n",
      " 31  koi_insol          9243 non-null   float64\n",
      " 32  koi_insol_err1     9243 non-null   float64\n",
      " 33  koi_insol_err2     9243 non-null   float64\n",
      " 34  koi_model_snr      9201 non-null   float64\n",
      " 35  koi_tce_plnt_num   9218 non-null   float64\n",
      " 36  koi_tce_delivname  9218 non-null   object \n",
      " 37  koi_steff          9201 non-null   float64\n",
      " 38  koi_steff_err1     9096 non-null   float64\n",
      " 39  koi_steff_err2     9081 non-null   float64\n",
      " 40  koi_slogg          9201 non-null   float64\n",
      " 41  koi_slogg_err1     9096 non-null   float64\n",
      " 42  koi_slogg_err2     9096 non-null   float64\n",
      " 43  koi_srad           9201 non-null   float64\n",
      " 44  koi_srad_err1      9096 non-null   float64\n",
      " 45  koi_srad_err2      9096 non-null   float64\n",
      " 46  ra                 9564 non-null   float64\n",
      " 47  dec                9564 non-null   float64\n",
      " 48  koi_kepmag         9563 non-null   float64\n",
      "dtypes: float64(39), int64(5), object(5)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "koi_teq_err1         9564\n",
       "koi_teq_err2         9564\n",
       "kepler_name          6817\n",
       "koi_score            1510\n",
       "koi_steff_err2        483\n",
       "koi_srad_err1         468\n",
       "koi_steff_err1        468\n",
       "koi_slogg_err2        468\n",
       "koi_slogg_err1        468\n",
       "koi_srad_err2         468\n",
       "koi_time0bk_err1      454\n",
       "koi_period_err1       454\n",
       "koi_period_err2       454\n",
       "koi_time0bk_err2      454\n",
       "koi_impact_err1       454\n",
       "koi_depth_err1        454\n",
       "koi_depth_err2        454\n",
       "koi_duration_err1     454\n",
       "koi_duration_err2     454\n",
       "koi_impact_err2       454\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df.isnull().sum().sort_values(ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a6c7133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "koi_disposition\n",
       "FALSE POSITIVE    4839\n",
       "CONFIRMED         2746\n",
       "CANDIDATE         1979\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['koi_disposition'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818c87d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_disposition', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
       "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
       "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
       "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
       "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
       "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
       "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
       "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
       "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
       "       'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar columnas irrelevantes y/o vacias\n",
    "columnas_despues = ['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec']\n",
    "cols_drop = ['rowid','kepid','kepoi_name','kepler_name','koi_pdisposition','koi_score','koi_teq_err1','koi_teq_err2','koi_tce_delivname','koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec']\n",
    "df = df.drop(columns=[c for c in cols_drop if c in df.columns])\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c9266c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribución de Confirmed vs Candidate')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualización de la distribución de las clases\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x='koi_disposition', data=df)\n",
    "plt.title('Distribución de Confirmed vs Candidate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d68cccb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9564, 37) (9564, 36) (9564,)\n",
      "Index(['koi_period', 'koi_period_err1', 'koi_period_err2', 'koi_time0bk',\n",
      "       'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact', 'koi_impact_err1',\n",
      "       'koi_impact_err2', 'koi_duration', 'koi_duration_err1',\n",
      "       'koi_duration_err2', 'koi_depth', 'koi_depth_err1', 'koi_depth_err2',\n",
      "       'koi_prad', 'koi_prad_err1', 'koi_prad_err2', 'koi_teq', 'koi_insol',\n",
      "       'koi_insol_err1', 'koi_insol_err2', 'koi_model_snr', 'koi_tce_plnt_num',\n",
      "       'koi_steff', 'koi_steff_err1', 'koi_steff_err2', 'koi_slogg',\n",
      "       'koi_slogg_err1', 'koi_slogg_err2', 'koi_srad', 'koi_srad_err1',\n",
      "       'koi_srad_err2', 'ra', 'dec', 'koi_kepmag'],\n",
      "      dtype='object')\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Reemplazá NaN con la media\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "df = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "# Split de features y target\n",
    "X = df.drop(columns=['koi_disposition',])\n",
    "y = df['koi_disposition']\n",
    "\n",
    "print(df.shape, X.shape, y.shape)\n",
    "print(X.columns)\n",
    "\n",
    "non_numeric_cols = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "print(non_numeric_cols)  # para ver algunas\n",
    "\n",
    "# Si solo son IDs o etiquetas drop\n",
    "X = X.drop(columns=non_numeric_cols)\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40b31cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd954a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6694, 36) (1435, 36) (1435, 36)\n"
     ]
    }
   ],
   "source": [
    "# separar en train, test y validation sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6607ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de y_train:\n",
      "koi_disposition\n",
      "FALSE POSITIVE    3387\n",
      "CONFIRMED         1922\n",
      "CANDIDATE         1385\n",
      "Name: count, dtype: int64\n",
      "Distribución de y_test:\n",
      "koi_disposition\n",
      "FALSE POSITIVE    726\n",
      "CONFIRMED         412\n",
      "CANDIDATE         297\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribución de y_train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"Distribución de y_test:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "def add_false_positives_half(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    X_fp,                      # numpy array de FP (mismas columnas/features)\n",
    "    groups_fp=None,            # opcional: array con kepid u otro ID por fila de X_fp\n",
    "    random_state=42\n",
    "):\n",
    "    n_fp = X_fp.shape[0]\n",
    "    y_fp = np.zeros(n_fp, dtype=int)     # todos los FP son clase 0\n",
    "\n",
    "    # Split 50/50 de FP (ideal: por grupos/estrellas)\n",
    "    if groups_fp is not None:\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=random_state)\n",
    "        idx = np.arange(n_fp)\n",
    "        fp_train_rel, fp_test_rel = next(gss.split(idx, groups=groups_fp))\n",
    "        fp_train_idx, fp_test_idx = idx[fp_train_rel], idx[fp_test_rel]\n",
    "    else:\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        perm = rng.permutation(n_fp)\n",
    "        half = n_fp // 2\n",
    "        fp_train_idx, fp_test_idx = perm[:half], perm[half:]\n",
    "\n",
    "    X_fp_train, y_fp_train = X_fp[fp_train_idx], y_fp[fp_train_idx]\n",
    "    X_fp_test,  y_fp_test  = X_fp[fp_test_idx],  y_fp[fp_test_idx]\n",
    "\n",
    "    # Concatenar a tus splits existentes\n",
    "    X_train_new = np.vstack([X_train, X_fp_train])\n",
    "    y_train_new = np.concatenate([y_train, y_fp_train])\n",
    "    X_test_new  = np.vstack([X_test,  X_fp_test])\n",
    "    y_test_new  = np.concatenate([y_test,  y_fp_test])\n",
    "\n",
    "    return X_train_new, y_train_new, X_test_new, y_test_new, fp_train_idx, fp_test_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "df30902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP shape: (4839, 36)\n"
     ]
    }
   ],
   "source": [
    "X_fp = df[df['koi_disposition'] == 'FALSE POSITIVE'].drop(columns=['koi_disposition'] + non_numeric_cols).values\n",
    "print(\"FP shape:\", X_fp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "489153a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6694, 36), (6694,), (1435, 36), (1435,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "defcea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, fp_train_idx, fp_test_idx = add_false_positives_half(\n",
    "    X_train, y_train, X_test, y_test, X_fp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04f4f07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de y_train:\n",
      "0    7191\n",
      "1    1922\n",
      "Name: count, dtype: int64\n",
      "Distribución de y_test:\n",
      "0                 2420\n",
      "FALSE POSITIVE     726\n",
      "CONFIRMED          412\n",
      "CANDIDATE          297\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribución de y_train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"Distribución de y_test:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b871e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "ffff 1\n",
      "Distribución de y_train:\n",
      "0    7191\n",
      "1    1922\n",
      "Name: count, dtype: int64\n",
      "Distribución de y_test:\n",
      "0    3443\n",
      "1     412\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], shape=(9113,), dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform all Positive or False Positive or Candidate labels to 1 or 0 (y_train and y_test dont have .map method)\n",
    "# if y_train == 'CONFIRMED' or y_train == 1 =1\n",
    "# if y_train == 'CANDIDATE' =0 or y_train == 0 =0\n",
    "# if y_train == 'FALSE POSITIVE' =0 or y_train == 0 =0\n",
    "for index, i in enumerate(y_train):\n",
    "    if i == 'CONFIRMED' or i == 1:\n",
    "        y_train[index] = 1\n",
    "        print(\"ffff\", y_train[index])\n",
    "    elif i == 'CANDIDATE' or i == 0:\n",
    "        y_train[index] = 0\n",
    "    elif i == 'FALSE POSITIVE' or i == 0:\n",
    "        y_train[index] = 0\n",
    "#y_train[3]=1\n",
    "\n",
    "for index, i in enumerate(y_test):\n",
    "    if i == 'CONFIRMED' or i == 1:\n",
    "        y_test[index] = 1\n",
    "        print(\"ffff\", y_test[index])\n",
    "    elif i == 'CANDIDATE' or i == 0:\n",
    "        y_test[index] = 0\n",
    "    elif i == 'FALSE POSITIVE' or i == 0:\n",
    "        y_test[index] = 0\n",
    "#y_train[3]=1\n",
    "\n",
    "#chequear si se cambiaron bien las etiquetas (fijarse cuantos 0 y 1 hay)()\n",
    "print(\"Distribución de y_train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"Distribución de y_test:\")\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fbe96b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de y_train:\n",
      "0    7191\n",
      "1    1922\n",
      "Name: count, dtype: int64\n",
      "Distribución de y_test:\n",
      "0    3443\n",
      "1     412\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribución de y_train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"Distribución de y_test:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "138b0242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9113, 36), (9113,), (3855, 36), (3855,))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6de6254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=1600, criterion='entropy', random_state=42, n_jobs=-1\n",
    "    )\n",
    "    et = ExtraTreesClassifier(\n",
    "        n_estimators=200, criterion='entropy', random_state=42, n_jobs=-1\n",
    "    )\n",
    "    adb = AdaBoostClassifier(\n",
    "        n_estimators=974, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=1600, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    meta = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    stack = StackingClassifier(\n",
    "        estimators=[('rf', rf), ('gb', gb)],\n",
    "        final_estimator=meta,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        passthrough=False\n",
    "    )\n",
    "    return {\n",
    "        'RandomForest': rf,\n",
    "        'ExtraTrees': et,\n",
    "        'AdaBoost': adb,\n",
    "        'Stacking': stack\n",
    "    }\n",
    "\n",
    "modelos = build_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85b8f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_metrics_at_threshold(y_true, y_proba, subgroup, thr):\n",
    "    y_pred = (y_proba >= thr).astype(int)\n",
    "    # Máscara por subgrupo en test\n",
    "    m_conf = subgroup == 'CONFIRMED'\n",
    "    m_cand = subgroup == 'CANDIDATE'\n",
    "    m_fp   = subgroup == 'FALSE POSITIVE'\n",
    "    \n",
    "    # TPR (recall) en confirmados (true label=1)\n",
    "    tpr_conf = ( (y_pred[m_conf] == 1).sum() / max(1, (y_true[m_conf] == 1).sum()) ) if m_conf.any() else np.nan\n",
    "    \n",
    "    # FPR en FP y en candidates (subgrupos con true label=0)\n",
    "    # (predice 1 cuando la verdad es 0 dentro de cada subgrupo)\n",
    "    def fpr(mask):\n",
    "        if not mask.any(): \n",
    "            return np.nan\n",
    "        tn_fp = (y_true[mask] == 0).sum()\n",
    "        if tn_fp == 0: \n",
    "            return np.nan\n",
    "        return ( (y_pred[mask] == 1).sum() / tn_fp )\n",
    "    \n",
    "    fpr_fp   = fpr(m_fp)\n",
    "    fpr_cand = fpr(m_cand)\n",
    "    \n",
    "    return tpr_conf, fpr_fp, fpr_cand\n",
    "\n",
    "def pick_operating_point(y_true, y_proba, subgroup, max_fpr_fp=0.10, grid=np.linspace(0.01, 0.99, 99)):\n",
    "    # Selecciona el umbral con FPR_FP <= max_fpr_fp que maximiza TPR_confirmed.\n",
    "    # Si ninguno cumple, elige el de menor FPR_FP; si empata, mayor TPR.\n",
    "    best = {'thr': None, 'tpr_conf': -1, 'fpr_fp': 1e9, 'fpr_cand': None}\n",
    "    candidates = []\n",
    "    for thr in grid:\n",
    "        tpr_conf, fpr_fp, fpr_cand = stratified_metrics_at_threshold(y_true, y_proba, subgroup, thr)\n",
    "        candidates.append((thr, tpr_conf, fpr_fp, fpr_cand))\n",
    "    \n",
    "    # Primero, los que cumplen el tope de FPR_FP\n",
    "    valid = [c for c in candidates if np.isfinite(c[2]) and c[2] <= max_fpr_fp]\n",
    "    if valid:\n",
    "        # Maximizá TPR_confirmed; tie-break: menor FPR_FP; luego umbral más alto\n",
    "        valid.sort(key=lambda x: (-(x[1] if x[1] is not None else -1), x[2], -x[0]))\n",
    "        thr, tpr_conf, fpr_fp, fpr_cand = valid[0]\n",
    "    else:\n",
    "        # Ninguno cumple → minimizá FPR_FP; tie-break: mayor TPR\n",
    "        filt = [c for c in candidates if np.isfinite(c[2])]\n",
    "        filt.sort(key=lambda x: (x[2], -(x[1] if x[1] is not None else -1), -x[0]))\n",
    "        thr, tpr_conf, fpr_fp, fpr_cand = filt[0]\n",
    "    \n",
    "    return {\n",
    "        'thr': thr,\n",
    "        'TPR_confirmed': tpr_conf,\n",
    "        'FPR_FP': fpr_fp,\n",
    "        'FPR_candidates': fpr_cand\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71754a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dtype: float64\n",
      "X_test  dtype: float64\n",
      "y_train dtype: object unique: [0 1]\n",
      "y_test  dtype: object unique: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train dtype:\", getattr(X_train, \"dtype\", None))\n",
    "print(\"X_test  dtype:\", getattr(X_test,  \"dtype\", None))\n",
    "print(\"y_train dtype:\", getattr(y_train, \"dtype\", None), \"unique:\", np.unique(y_train))\n",
    "print(\"y_test  dtype:\", getattr(y_test,  \"dtype\", None), \"unique:\", np.unique(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "08ef8e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de y_train:\n",
      "0    7191\n",
      "1    1922\n",
      "Name: count, dtype: int64\n",
      "Distribución de y_test:\n",
      "0    3443\n",
      "1     412\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribución de y_train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"Distribución de y_test:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8e68b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train tiene NaNs? False\n",
      "y_test tiene NaNs? False\n"
     ]
    }
   ],
   "source": [
    "#chequear si hay nans en y_train o y_test\n",
    "print(\"y_train tiene NaNs?\", pd.isnull(y_train).any())\n",
    "print(\"y_test tiene NaNs?\", pd.isnull(y_test).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3bf0acfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: type=<class 'numpy.ndarray'>, shape=(9113,), np.dtype=object, sk_type=unknown\n",
      "y_test: type=<class 'numpy.ndarray'>, shape=(3855,), np.dtype=object, sk_type=unknown\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def diag_y(y, name):\n",
    "    a = np.asarray(y)\n",
    "    print(f\"{name}: type={type(y)}, shape={a.shape}, np.dtype={a.dtype}, sk_type={type_of_target(a)}\")\n",
    "\n",
    "diag_y(y_train, \"y_train\")\n",
    "diag_y(y_test,  \"y_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27aed6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train sk_type: binary   uniques: [0 1]\n",
      "y_test  sk_type: binary   uniques: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Forzar 1D + int64 \"duro\" en y\n",
    "y_train = pd.Series(y_train).astype(\"int64\").to_numpy().ravel()\n",
    "y_test  = pd.Series(y_test ).astype(\"int64\").to_numpy().ravel()\n",
    "\n",
    "# (Opcional pero recomendable) asegurar X como float NumPy 2D\n",
    "X_train = np.asarray(X_train, dtype=float)\n",
    "X_test  = np.asarray(X_test,  dtype=float)\n",
    "\n",
    "# Chequeo post-fix\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "print(\"y_train sk_type:\", type_of_target(y_train), \"  uniques:\", np.unique(y_train))\n",
    "print(\"y_test  sk_type:\", type_of_target(y_test),  \"  uniques:\", np.unique(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "277aa8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Entrenando RandomForest_fp ===\n",
      "y_train distrib: {0: 7191, 1: 1922}\n",
      "RandomForest_fp classes_ aprendidas: [0 1]\n",
      "Guardado: models\\fps\\RandomForest_fp.pkl\n",
      "Umbral elegido: 0.383 | PR-AUC=0.9250 | ROC-AUC=0.9906\n",
      "[0.5]     Acc=0.968 Prec=0.880 Rec=0.816 F1=0.846  CM=[[3397, 46], [76, 336]]\n",
      "[@thr]    Acc=0.970 Prec=0.836 Rec=0.891 F1=0.863 CM=[[3371, 72], [45, 367]]\n",
      "\n",
      "=== Entrenando ExtraTrees_fp ===\n",
      "y_train distrib: {0: 7191, 1: 1922}\n",
      "ExtraTrees_fp classes_ aprendidas: [0 1]\n",
      "Guardado: models\\fps\\ExtraTrees_fp.pkl\n",
      "Umbral elegido: 0.375 | PR-AUC=0.9213 | ROC-AUC=0.9902\n",
      "[0.5]     Acc=0.969 Prec=0.869 Rec=0.835 F1=0.851  CM=[[3391, 52], [68, 344]]\n",
      "[@thr]    Acc=0.968 Prec=0.813 Rec=0.905 F1=0.856 CM=[[3357, 86], [39, 373]]\n",
      "\n",
      "=== Entrenando AdaBoost_fp ===\n",
      "y_train distrib: {0: 7191, 1: 1922}\n",
      "AdaBoost_fp classes_ aprendidas: [0 1]\n",
      "Guardado: models\\fps\\AdaBoost_fp.pkl\n",
      "Umbral elegido: 0.489 | PR-AUC=0.8878 | ROC-AUC=0.9862\n",
      "[0.5]     Acc=0.964 Prec=0.859 Rec=0.796 F1=0.826  CM=[[3389, 54], [84, 328]]\n",
      "[@thr]    Acc=0.965 Prec=0.826 Rec=0.854 F1=0.840 CM=[[3369, 74], [60, 352]]\n",
      "\n",
      "=== Entrenando Stacking_fp ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 315\u001b[39m\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results, results_by_subgroup\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# USO: reemplazá con tus arrays\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[38;5;66;03m# X_train, y_train, X_test, y_test = ...  # ya los tenés\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;66;03m# subgroup_test = None  # o np.array([...]) con etiquetas 'CONFIRMED'/'CANDIDATE'/'FALSE POSITIVE'\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m results, results_by_subgroup = \u001b[43mtrain_save_eval_all\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubgroup_test\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# si no lo tenés, poné None y la tabla estratificada no se genera\u001b[39;49;00m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_fpr_fp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.10\u001b[39;49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# ajustá el tope de FPR sobre FP\u001b[39;49;00m\n\u001b[32m    319\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResumen por modelo:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, results.to_string(index=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results_by_subgroup.empty:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 191\u001b[39m, in \u001b[36mtrain_save_eval_all\u001b[39m\u001b[34m(X_train, y_train, X_test, y_test, subgroup_test, max_fpr_fp)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, clf \u001b[38;5;129;01min\u001b[39;00m models.items():\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Entrenando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# Dentro de train_save_eval_all(), justo después de clf.fit(X_train, y_train):\u001b[39;00m\n\u001b[32m    193\u001b[39m     unique, counts = np.unique(y_train, return_counts=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matir\\OneDrive\\Documentos\\NASA\\Exoplanet detection using AI\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:706\u001b[39m, in \u001b[36mStackingClassifier.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    703\u001b[39m     \u001b[38;5;28mself\u001b[39m.classes_ = \u001b[38;5;28mself\u001b[39m._label_encoder.classes_\n\u001b[32m    704\u001b[39m     y_encoded = \u001b[38;5;28mself\u001b[39m._label_encoder.transform(y)\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matir\\OneDrive\\Documentos\\NASA\\Exoplanet detection using AI\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matir\\OneDrive\\Documentos\\NASA\\Exoplanet detection using AI\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:211\u001b[39m, in \u001b[36m_BaseStacking.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    206\u001b[39m             \u001b[38;5;28mself\u001b[39m.estimators_.append(estimator)\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;66;03m# Fit the base estimators on the whole training data. Those\u001b[39;00m\n\u001b[32m    209\u001b[39m     \u001b[38;5;66;03m# base estimators will be used in transform, predict, and\u001b[39;00m\n\u001b[32m    210\u001b[39m     \u001b[38;5;66;03m# predict_proba. They are exposed publicly.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28mself\u001b[39m.estimators_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_estimators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdrop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28mself\u001b[39m.named_estimators_ = Bunch()\n\u001b[32m    220\u001b[39m est_fitted_idx = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matir\\OneDrive\\Documentos\\NASA\\Exoplanet detection using AI\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matir\\OneDrive\\Documentos\\NASA\\Exoplanet detection using AI\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matir\\OneDrive\\Documentos\\NASA\\Exoplanet detection using AI\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matir\\OneDrive\\Documentos\\NASA\\Exoplanet detection using AI\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json, os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix,\n",
    "    precision_recall_curve, classification_report\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "MODELS_DIR = Path(\"models/fps\")\n",
    "MODELS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "\n",
    "def build_subgroup_table(y_true, y_pred, subgroup):\n",
    "    \"\"\"Devuelve una tabla con TP, TN, FP, FN y tasas por subgrupo del test.\"\"\"\n",
    "    rows = []\n",
    "    subcats = pd.Series(subgroup).astype(str).unique().tolist()\n",
    "    for sg in subcats:\n",
    "        m = (subgroup == sg)\n",
    "        yt = y_true[m]\n",
    "        yp = y_pred[m]\n",
    "        n = int(m.sum())\n",
    "        if n == 0:\n",
    "            continue\n",
    "        P = int((yt == 1).sum())\n",
    "        N = int((yt == 0).sum())\n",
    "        TP = int(((yt == 1) & (yp == 1)).sum())\n",
    "        FN = int(((yt == 1) & (yp == 0)).sum())\n",
    "        FP = int(((yt == 0) & (yp == 1)).sum())\n",
    "        TN = int(((yt == 0) & (yp == 0)).sum())\n",
    "        tpr = TP / (TP + FN) if (TP + FN) > 0 else np.nan      # recall (si hay positivos)\n",
    "        fpr = FP / (FP + TN) if (FP + TN) > 0 else np.nan      # tasa de falsos positivos (si hay negativos)\n",
    "        tnr = TN / (TN + FP) if (TN + FP) > 0 else np.nan\n",
    "        fnr = FN / (FN + TP) if (FN + TP) > 0 else np.nan\n",
    "        acc_sg = (TP + TN) / n if n > 0 else np.nan\n",
    "        ppr = (TP + FP) / n  # predicted positive rate\n",
    "        rows.append({\n",
    "            \"subgroup\": sg,\n",
    "            \"N\": n,\n",
    "            \"P(true=1)\": P,\n",
    "            \"N(true=0)\": N,\n",
    "            \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
    "            \"Accuracy_sg\": round(float(acc_sg), 4),\n",
    "            \"TPR_recall\": round(float(tpr), 4) if np.isfinite(tpr) else None,\n",
    "            \"FPR\": round(float(fpr), 4) if np.isfinite(fpr) else None,\n",
    "            \"TNR\": round(float(tnr), 4) if np.isfinite(tnr) else None,\n",
    "            \"FNR\": round(float(fnr), 4) if np.isfinite(fnr) else None,\n",
    "            \"PredPosRate\": round(float(ppr), 4),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def safe_proba(clf, X, pos_label=1):\n",
    "    import numpy as np\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        proba = clf.predict_proba(X)\n",
    "        classes = getattr(clf, \"classes_\", None)\n",
    "        if proba.ndim == 2 and classes is not None:\n",
    "            if proba.shape[1] == 2:\n",
    "                j = int(np.where(classes == pos_label)[0][0])\n",
    "                return proba[:, j]\n",
    "            if proba.shape[1] == 1:\n",
    "                learned = classes[0] if classes is not None and len(classes)==1 else None\n",
    "                return np.full(X.shape[0], 1.0 if learned == pos_label else 0.0, dtype=float)\n",
    "        return proba.ravel().astype(float)\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        z = clf.decision_function(X)\n",
    "        z = (z - z.min()) / (z.max() - z.min() + 1e-9)\n",
    "        return z.astype(float)\n",
    "    return clf.predict(X).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "def f1_from_pr(prec, rec):\n",
    "    denom = (prec + rec)\n",
    "    denom[denom == 0] = 1e-9\n",
    "    return 2 * prec * rec / denom\n",
    "\n",
    "def choose_threshold_max_f1(y_true, y_proba):\n",
    "    prec, rec, thr = precision_recall_curve(y_true, y_proba)\n",
    "    f1 = f1_from_pr(prec[:-1], rec[:-1])  # descarta último punto (sin threshold)\n",
    "    i = np.argmax(f1)\n",
    "    return float(thr[i])\n",
    "\n",
    "def stratified_metrics_at_thr(y_true, y_proba, subgroup, thr):\n",
    "    y_pred = (y_proba >= thr).astype(int)\n",
    "    # Masks\n",
    "    m_conf = subgroup == 'CONFIRMED'\n",
    "    m_cand = subgroup == 'CANDIDATE'\n",
    "    m_fp   = subgroup == 'FALSE POSITIVE'\n",
    "    # TPR en confirmados (clase 1)\n",
    "    tpr_conf = np.nan\n",
    "    if m_conf.any():\n",
    "        denom = max(1, (y_true[m_conf] == 1).sum())\n",
    "        tpr_conf = ( (y_pred[m_conf] == 1).sum() / denom )\n",
    "    # FPR en FP y CAND (casos true=0 pred=1)\n",
    "    def fpr(mask):\n",
    "        if not mask.any(): return np.nan\n",
    "        neg = (y_true[mask] == 0).sum()\n",
    "        if neg == 0: return np.nan\n",
    "        return ( (y_pred[mask] == 1).sum() / neg )\n",
    "    return float(tpr_conf), float(fpr(m_fp)), float(fpr(m_cand))\n",
    "\n",
    "def choose_threshold_with_fp_cap(y_true, y_proba, subgroup, max_fpr_fp=0.10):\n",
    "    grid = np.linspace(0.01, 0.99, 99)\n",
    "    candidates = []\n",
    "    for thr in grid:\n",
    "        tpr_c, fpr_fp, fpr_cand = stratified_metrics_at_thr(y_true, y_proba, subgroup, thr)\n",
    "        candidates.append((thr, tpr_c, fpr_fp, fpr_cand))\n",
    "    # primero los que cumplen el cap\n",
    "    valid = [c for c in candidates if np.isfinite(c[2]) and c[2] <= max_fpr_fp]\n",
    "    if valid:\n",
    "        # max TPR_conf, tie-break: menor FPR_FP, luego thr más alto\n",
    "        valid.sort(key=lambda x: (-(x[1] if np.isfinite(x[1]) else -1), x[2], -x[0]))\n",
    "        return {\n",
    "            'thr': float(valid[0][0]),\n",
    "            'TPR_confirmed': float(valid[0][1]),\n",
    "            'FPR_FP': float(valid[0][2]),\n",
    "            'FPR_candidates': float(valid[0][3]),\n",
    "        }\n",
    "    # si ninguno cumple, minimizá FPR_FP; tie-break: mayor TPR_conf\n",
    "    candidates = [c for c in candidates if np.isfinite(c[2])]\n",
    "    candidates.sort(key=lambda x: (x[2], -(x[1] if np.isfinite(x[1]) else -1), -x[0]))\n",
    "    best = candidates[0]\n",
    "    return {\n",
    "        'thr': float(best[0]),\n",
    "        'TPR_confirmed': float(best[1]),\n",
    "        'FPR_FP': float(best[2]),\n",
    "        'FPR_candidates': float(best[3]),\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# Construcción de modelos\n",
    "# =========================\n",
    "def build_models():\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=1600, criterion='entropy', random_state=RANDOM_STATE, n_jobs=-1\n",
    "    )\n",
    "    et = ExtraTreesClassifier(\n",
    "        n_estimators=200, criterion='entropy', random_state=RANDOM_STATE, n_jobs=-1\n",
    "    )\n",
    "    adb = AdaBoostClassifier(\n",
    "        n_estimators=974, learning_rate=0.1, random_state=RANDOM_STATE\n",
    "    )\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=1600, learning_rate=0.1, random_state=RANDOM_STATE\n",
    "    )\n",
    "    meta = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
    "    stack = StackingClassifier(\n",
    "        estimators=[('rf', rf), ('gb', gb)],\n",
    "        final_estimator=meta,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        passthrough=False\n",
    "    )\n",
    "    return {\n",
    "        \"RandomForest_fp\": rf,\n",
    "        \"ExtraTrees_fp\": et,\n",
    "        \"AdaBoost_fp\": adb,\n",
    "        \"Stacking_fp\": stack\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# Entrenar, guardar, evaluar\n",
    "# =========================\n",
    "def train_save_eval_all(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    subgroup_test=None,    # np.array(['CONFIRMED','CANDIDATE','FALSE POSITIVE',...])\n",
    "    max_fpr_fp=0.10\n",
    "):\n",
    "    models = build_models()\n",
    "    rows_summary = []\n",
    "    all_subgroups = []  # para juntar tablas de todos los modelos\n",
    "\n",
    "    for name, clf in models.items():\n",
    "        print(f\"\\n=== Entrenando {name} ===\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        # Dentro de train_save_eval_all(), justo después de clf.fit(X_train, y_train):\n",
    "        unique, counts = np.unique(y_train, return_counts=True)\n",
    "        print(f\"y_train distrib: {dict(zip(unique.tolist(), counts.tolist()))}\")\n",
    "\n",
    "        classes = getattr(clf, \"classes_\", None)\n",
    "        print(f\"{name} classes_ aprendidas: {classes}\")\n",
    "\n",
    "        if classes is not None and len(classes) < 2:\n",
    "            print(f\"⚠️  Aviso: {name} se entrenó con UNA sola clase ({classes[0]}). \"\n",
    "                f\"Revisá tu split: asegurá que y_train tenga 0s y 1s.\")\n",
    "\n",
    "        # Guardar modelo\n",
    "        model_path = MODELS_DIR / f\"{name}.pkl\"\n",
    "        joblib.dump(clf, model_path)\n",
    "        print(f\"Guardado: {model_path}\")\n",
    "\n",
    "        # Probabilidades\n",
    "        y_proba = safe_proba(clf, X_test)\n",
    "\n",
    "        # Métricas globales @0.5\n",
    "        y_pred05 = (y_proba >= 0.5).astype(int)\n",
    "        acc = accuracy_score(y_test, y_pred05)\n",
    "        prec = precision_score(y_test, y_pred05, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred05, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred05, zero_division=0)\n",
    "        cm = confusion_matrix(y_test, y_pred05)\n",
    "        try:\n",
    "            roc = roc_auc_score(y_test, y_proba)\n",
    "        except:\n",
    "            roc = np.nan\n",
    "        ap = average_precision_score(y_test, y_proba)\n",
    "\n",
    "        # Elegir umbral operativo\n",
    "        meta_thr = {}\n",
    "        if subgroup_test is not None:\n",
    "            meta_thr = choose_threshold_with_fp_cap(y_test, y_proba, subgroup_test, max_fpr_fp=max_fpr_fp)\n",
    "            thr = meta_thr['thr']\n",
    "        else:\n",
    "            thr = choose_threshold_max_f1(y_test, y_proba)\n",
    "            meta_thr = {\"thr\": thr}\n",
    "\n",
    "        # Métricas al umbral elegido\n",
    "        y_pred_thr = (y_proba >= thr).astype(int)\n",
    "        acc_thr = accuracy_score(y_test, y_pred_thr)\n",
    "        prec_thr = precision_score(y_test, y_pred_thr, zero_division=0)\n",
    "        rec_thr = recall_score(y_test, y_pred_thr, zero_division=0)\n",
    "        f1_thr = f1_score(y_test, y_pred_thr, zero_division=0)\n",
    "        cm_thr = confusion_matrix(y_test, y_pred_thr)\n",
    "\n",
    "        # Report corto\n",
    "        print(f\"Umbral elegido: {thr:.3f} | PR-AUC={ap:.4f} | ROC-AUC={roc:.4f}\")\n",
    "        print(f\"[0.5]     Acc={acc:.3f} Prec={prec:.3f} Rec={rec:.3f} F1={f1:.3f}  CM={cm.tolist()}\")\n",
    "        print(f\"[@thr]    Acc={acc_thr:.3f} Prec={prec_thr:.3f} Rec={rec_thr:.3f} F1={f1_thr:.3f} CM={cm_thr.tolist()}\")\n",
    "        if subgroup_test is not None:\n",
    "            print(f\"          TPR_confirmed={meta_thr['TPR_confirmed']:.3f}  FPR_FP={meta_thr['FPR_FP']:.3f}  FPR_candidates={meta_thr['FPR_candidates']:.3f}\")\n",
    "\n",
    "        # Guardar metadatos (umbral y métricas)\n",
    "        meta_to_save = {\n",
    "            \"threshold\": float(thr),\n",
    "            \"PR_AUC\": float(ap),\n",
    "            \"ROC_AUC\": float(roc) if roc==roc else None,\n",
    "            \"metrics@0.5\": {\n",
    "                \"accuracy\": float(acc), \"precision\": float(prec),\n",
    "                \"recall\": float(rec), \"f1\": float(f1),\n",
    "                \"confusion_matrix\": cm.tolist()\n",
    "            },\n",
    "            \"metrics@thr\": {\n",
    "                \"accuracy\": float(acc_thr), \"precision\": float(prec_thr),\n",
    "                \"recall\": float(rec_thr), \"f1\": float(f1_thr),\n",
    "                \"confusion_matrix\": cm_thr.tolist()\n",
    "            }\n",
    "        }\n",
    "        # añade TPR/FPR si existen\n",
    "        for k in (\"TPR_confirmed\",\"FPR_FP\",\"FPR_candidates\"):\n",
    "            if k in meta_thr:\n",
    "                meta_to_save[k] = float(meta_thr[k])\n",
    "\n",
    "        with open(MODELS_DIR / f\"{name}_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(meta_to_save, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        # --- NUEVO: tabla estratificada por subgrupo @thr ---\n",
    "        if subgroup_test is not None:\n",
    "            df_sg = build_subgroup_table(y_test, y_pred_thr, subgroup_test)\n",
    "            df_sg.insert(0, \"model\", name)\n",
    "            all_subgroups.append(df_sg)\n",
    "            # guardar CSV por modelo\n",
    "            csv_path = MODELS_DIR / f\"{name}_subgroup_eval.csv\"\n",
    "            df_sg.to_csv(csv_path, index=False)\n",
    "            print(f\"Tabla por subgrupo guardada en: {csv_path}\")\n",
    "\n",
    "        # Para tabla resumen\n",
    "        row = {\n",
    "            \"model\": name,\n",
    "            \"PR_AUC\": round(float(ap), 4),\n",
    "            \"ROC_AUC\": round(float(roc), 4) if roc==roc else None,\n",
    "            \"thr*\": round(float(thr), 3),\n",
    "            \"Acc@0.5\": round(float(acc), 4),\n",
    "            \"F1@0.5\": round(float(f1), 4),\n",
    "            \"Acc@thr\": round(float(acc_thr), 4),\n",
    "            \"F1@thr\": round(float(f1_thr), 4),\n",
    "        }\n",
    "        if subgroup_test is not None:\n",
    "            row.update({\n",
    "                \"TPR_confirmed@thr\": round(float(meta_thr['TPR_confirmed']), 4),\n",
    "                \"FPR_FP@thr\": round(float(meta_thr['FPR_FP']), 4),\n",
    "                \"FPR_cand@thr\": round(float(meta_thr['FPR_candidates']), 4),\n",
    "            })\n",
    "        rows_summary.append(row)\n",
    "\n",
    "    results = pd.DataFrame(rows_summary).sort_values([\"F1@thr\",\"PR_AUC\"], ascending=False)\n",
    "    results_by_subgroup = pd.concat(all_subgroups, ignore_index=True) if all_subgroups else pd.DataFrame()\n",
    "    # También guardamos la tabla completa por subgrupo\n",
    "    if not results_by_subgroup.empty:\n",
    "        results_by_subgroup.to_csv(MODELS_DIR / \"ALL_MODELS_subgroup_eval.csv\", index=False)\n",
    "    return results, results_by_subgroup\n",
    "\n",
    "# =========================\n",
    "# USO: reemplazá con tus arrays\n",
    "# =========================\n",
    "# X_train, y_train, X_test, y_test = ...  # ya los tenés\n",
    "# subgroup_test = None  # o np.array([...]) con etiquetas 'CONFIRMED'/'CANDIDATE'/'FALSE POSITIVE'\n",
    "\n",
    "\n",
    "results, results_by_subgroup = train_save_eval_all(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    subgroup_test=None,   # si no lo tenés, poné None y la tabla estratificada no se genera\n",
    "    max_fpr_fp=0.10                # ajustá el tope de FPR sobre FP\n",
    ")\n",
    "\n",
    "print(\"\\nResumen por modelo:\\n\", results.to_string(index=False))\n",
    "if not results_by_subgroup.empty:\n",
    "    print(\"\\nMétricas por subgrupo (primeras filas):\\n\", results_by_subgroup.head().to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eea675a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
