{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a660e6a",
   "metadata": {},
   "source": [
    "\n",
    "# Exoplanet ML — FAST (carga de modelos pre-entrenados + evaluación/umbral)\n",
    "\n",
    "**Fecha:** 2025-10-04 20:10:34\n",
    "\n",
    "Versión rápida para **evitar reentrenar**. Permite cargar tus `.pkl` ya entrenados y continuar con:\n",
    "- **OOF evaluation** (si tenés `X,y`),\n",
    "- **Curva PR** + **selección de umbral** (para bajar falsos positivos),\n",
    "- **Calibración** de probabilidades y export de artefactos.\n",
    "\n",
    "> Si preferís reentrenar, podés saltarte la celda de carga de pre-entrenados y usar los modelos definidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Setup & reproducibilidad ====\n",
    "import os, warnings, json, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, precision_recall_curve,\n",
    "                             confusion_matrix, precision_score, recall_score, f1_score, roc_curve)\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "MODELS_DIR = Path(\"models\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "REGISTRY_PATH = MODELS_DIR / \"registry.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6623f9",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d2c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Carga de datos ====\n",
    "# OPCIÓN A (CSV): descomentar y definir\n",
    "# DATA_PATH = \"data/dataset.csv\"\n",
    "# TARGET_COL = \"label\"\n",
    "# df = pd.read_csv(DATA_PATH)\n",
    "# y = df[TARGET_COL].astype(int).values\n",
    "# feature_cols = [c for c in df.columns if c != TARGET_COL]\n",
    "# X = df[feature_cols].values\n",
    "\n",
    "# OPCIÓN B (X, y ya construidos en memoria): si ya están en el entorno, no hay nada que hacer aquí.\n",
    "\n",
    "# OPCIÓN C (usar features.json para columnas) — si lo tenés disponible:\n",
    "feature_cols = None\n",
    "if Path(\"/mnt/data/features.json\").exists():\n",
    "    try:\n",
    "        with open(\"/mnt/data/features.json\", \"r\") as f:\n",
    "            feature_cols = json.load(f)\n",
    "            print(\"features.json detectado con\", len(feature_cols), \"features.\")\n",
    "    except Exception as e:\n",
    "        print(\"No se pudo leer features.json:\", e)\n",
    "\n",
    "# Chequeo de X,y\n",
    "try:\n",
    "    X\n",
    "    y\n",
    "    print(\"X,y ya existen. Shape:\", np.shape(X), \"y positivos:\", int(np.sum(y)))\n",
    "    if feature_cols is not None and isinstance(X, np.ndarray) and X.shape[1] == len(feature_cols):\n",
    "        print(\"Las columnas de features.json coinciden con X.shape[1].\")\n",
    "except NameError:\n",
    "    print(\">> Definí X,y o cargalos desde CSV. Ver instrucciones arriba.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745b5983",
   "metadata": {},
   "source": [
    "## Protocolo de evaluación y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3e34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def pr_metrics_from_probs(y_true, y_prob, threshold=0.5):\n",
    "    ap = average_precision_score(y_true, y_prob)\n",
    "    roc = roc_auc_score(y_true, y_prob)\n",
    "    y_hat = (y_prob >= threshold).astype(int)\n",
    "    prec = precision_score(y_true, y_hat, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_hat, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_hat, zero_division=0)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
    "    return {\"PR_AUC\": ap, \"ROC_AUC\": roc, \"precision@thr\": prec, \"recall@thr\": rec, \"F1@thr\": f1,\n",
    "            \"TP\": int(tp), \"FP\": int(fp), \"FN\": int(fn), \"TN\": int(tn), \"threshold\": float(threshold)}\n",
    "\n",
    "def pick_threshold_for_min_precision(y_true, y_prob, min_precision=0.90):\n",
    "    prec, rec, thr = precision_recall_curve(y_true, y_prob)\n",
    "    mask = prec >= min_precision\n",
    "    thr_ok = thr[mask].min() if mask.any() else 0.5\n",
    "    return float(thr_ok)\n",
    "\n",
    "def plot_pr_curves(models_probs, y_true):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    for name, probs in models_probs.items():\n",
    "        prec, rec, _ = precision_recall_curve(y_true, probs)\n",
    "        ap = average_precision_score(y_true, probs)\n",
    "        plt.plot(rec, prec, label=f\"{name} (AP={ap:.3f})\")\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Curva Precisión–Recall (OOF)\")\n",
    "    plt.legend(); plt.grid(True, alpha=0.3); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbff016",
   "metadata": {},
   "source": [
    "## Definición de modelos (opcional si no cargás pre-entrenados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d0a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf  = RandomForestClassifier(n_estimators=600, criterion='entropy', random_state=42, n_jobs=-1, class_weight=None)\n",
    "et  = ExtraTreesClassifier(n_estimators=600, criterion='entropy', random_state=42, n_jobs=-1)\n",
    "ada = AdaBoostClassifier(n_estimators=600, learning_rate=0.1, random_state=42)\n",
    "\n",
    "meta = LogisticRegression(max_iter=2000)\n",
    "stack = StackingClassifier(estimators=[('rf', rf), ('et', et), ('ada', ada)],\n",
    "                           final_estimator=meta, cv=cv, passthrough=False, n_jobs=-1)\n",
    "\n",
    "models = {\"RandomForest\": rf, \"ExtraTrees\": et, \"AdaBoost\": ada, \"Stacking\": stack}\n",
    "print(\"Modelos definidos (para reentrenar si querés):\", list(models.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7230b",
   "metadata": {},
   "source": [
    "## (Rápido) Cargar modelos pre-entrenados desde `.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bee005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Busca en /mnt/data y en models/ varias variantes de nombre, incluidas las que subiste.\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "CANDIDATE_PATHS = {\n",
    "    \"RandomForest\": [\n",
    "        Path(\"/mnt/data/random_forest.pkl\"),\n",
    "        Path(\"/mnt/data/Random Forest_model.pkl\"),\n",
    "        Path(\"models/random_forest.pkl\"),\n",
    "    ],\n",
    "    \"ExtraTrees\": [\n",
    "        Path(\"/mnt/data/extra_trees.pkl\"),\n",
    "        Path(\"/mnt/data/Extra Trees_model.pkl\"),\n",
    "        Path(\"models/extra_trees.pkl\"),\n",
    "    ],\n",
    "    \"AdaBoost\": [\n",
    "        Path(\"/mnt/data/adaboost.pkl\"),\n",
    "        Path(\"/mnt/data/AdaBoost_model.pkl\"),\n",
    "        Path(\"models/adaboost.pkl\"),\n",
    "    ],\n",
    "    \"Stacking\": [\n",
    "        Path(\"/mnt/data/stacking.pkl\"),\n",
    "        Path(\"models/stacking.pkl\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "loaded = {}\n",
    "for name, paths in CANDIDATE_PATHS.items():\n",
    "    loaded_flag = False\n",
    "    for p in paths:\n",
    "        if p.exists():\n",
    "            try:\n",
    "                m = joblib.load(p)\n",
    "                loaded[name] = m\n",
    "                print(f\"✅ Cargado modelo preentrenado: {name} desde {p}\")\n",
    "                loaded_flag = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ No se pudo cargar {name} desde {p}: {e}\")\n",
    "    if not loaded_flag:\n",
    "        print(f\"⚠️ No se encontró archivo válido para {name} (se usará el modelo definido si es necesario).\")\n",
    "\n",
    "if loaded:\n",
    "    models = loaded  # sobrescribe el diccionario models\n",
    "    print(\"\\nUsando modelos preentrenados para la evaluación.\")\n",
    "else:\n",
    "    print(\"\\nNo se encontraron modelos preentrenados, se usarán los modelos definidos (y deberás entrenarlos).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30f3590",
   "metadata": {},
   "source": [
    "## Evaluación OOF (mismo CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a61bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    X; y\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Definí X,y antes de correr esta celda. Ver 'Carga de datos'.\")\n",
    "\n",
    "oof_probs = {}\n",
    "scores_tbl = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([(\"clf\", clf)])  # agrega scaler si hace falta\n",
    "    probs = cross_val_predict(pipe, X, y, cv=cv, method=\"predict_proba\")[:,1]\n",
    "    oof_probs[name] = probs\n",
    "    metrics = pr_metrics_from_probs(y, probs, threshold=0.5)\n",
    "    scores_tbl.append({\"model\": name, **metrics})\n",
    "    print(f\"{name}  -> PR-AUC={metrics['PR_AUC']:.4f} | ROC-AUC={metrics['ROC_AUC']:.4f} | \"\n",
    "          f\"Prec@0.5={metrics['precision@thr']:.3f} | Recall@0.5={metrics['recall@thr']:.3f}\")\n",
    "\n",
    "scores_df = pd.DataFrame(scores_tbl).sort_values(\"PR_AUC\", ascending=False).reset_index(drop=True)\n",
    "scores_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d2b316",
   "metadata": {},
   "source": [
    "### Curvas PR (comparación OOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e4f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_pr_curves(oof_probs, y_true=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a08baea",
   "metadata": {},
   "source": [
    "## Selección de modelo + umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1707b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_name = scores_df.loc[0, \"model\"]\n",
    "print(\"Mejor por PR-AUC (OOF):\", best_name)\n",
    "\n",
    "MIN_PRECISION = 0.90\n",
    "thr_best = pick_threshold_for_min_precision(y, oof_probs[best_name], min_precision=MIN_PRECISION)\n",
    "print(f\"Umbral elegido para {best_name} con precisión ≥ {MIN_PRECISION:.2f}: {thr_best:.3f}\")\n",
    "\n",
    "op_metrics = pr_metrics_from_probs(y, oof_probs[best_name], threshold=thr_best)\n",
    "pd.DataFrame([op_metrics])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f6cf7e",
   "metadata": {},
   "source": [
    "## Calibración y entrenamiento final (full data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff889ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base = models[best_name]\n",
    "pipe = Pipeline([(\"clf\", base)])  # agrega scaler si tus features lo requieren\n",
    "\n",
    "calibrated = CalibratedClassifierCV(pipe, method=\"isotonic\", cv=cv)\n",
    "calibrated.fit(X, y)\n",
    "\n",
    "from datetime import datetime\n",
    "final_model_path = Path(\"models\") / f\"{best_name.lower()}_calibrated.pkl\"\n",
    "joblib.dump(calibrated, final_model_path)\n",
    "print(\"✅ Modelo calibrado guardado en:\", final_model_path)\n",
    "\n",
    "export = {\n",
    "    \"model_name\": best_name,\n",
    "    \"threshold\": float(thr_best),\n",
    "    \"feature_cols\": feature_cols if feature_cols is not None else (list(range(X.shape[1])) if hasattr(X, 'shape') else None),\n",
    "    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"min_precision_target\": float(MIN_PRECISION)\n",
    "}\n",
    "with open(Path(\"models\") / \"inference_config.json\", \"w\") as f:\n",
    "    json.dump(export, f, indent=2)\n",
    "print(\"✅ inference_config.json guardado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad08db",
   "metadata": {},
   "source": [
    "## Registry de experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1439c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "registry_entry = {\n",
    "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"cv\": {\"n_splits\": 5, \"shuffle\": True, \"random_state\": 42},\n",
    "    \"scores\": scores_df.to_dict(orient=\"records\"),\n",
    "    \"selected_model\": best_name,\n",
    "    \"operating_point\": {\"threshold\": float(thr_best), **pr_metrics_from_probs(y, oof_probs[best_name], threshold=thr_best)},\n",
    "    \"artifacts\": {\"model_path\": f\"models/{best_name.lower()}_calibrated.pkl\", \"inference_config\": \"models/inference_config.json\"}\n",
    "}\n",
    "\n",
    "REGISTRY_PATH = Path(\"models\") / \"registry.json\"\n",
    "if REGISTRY_PATH.exists():\n",
    "    try:\n",
    "        reg = json.loads(REGISTRY_PATH.read_text())\n",
    "        if not isinstance(reg, list): reg = [reg]\n",
    "    except Exception:\n",
    "        reg = []\n",
    "else:\n",
    "    reg = []\n",
    "\n",
    "reg.append(registry_entry)\n",
    "REGISTRY_PATH.write_text(json.dumps(reg, indent=2))\n",
    "print(\"✅ Registry actualizado en\", REGISTRY_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9a765c",
   "metadata": {},
   "source": [
    "## Inferencia con umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model_and_config(model_path=None, config_path=None):\n",
    "    model_path = model_path or (Path(\"models\") / f\"{best_name.lower()}_calibrated.pkl\")\n",
    "    config_path = config_path or (Path(\"models\") / \"inference_config.json\")\n",
    "    model = joblib.load(model_path)\n",
    "    with open(config_path, \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "    return model, cfg\n",
    "\n",
    "def predict_with_threshold(X_new, model, threshold):\n",
    "    probs = model.predict_proba(X_new)[:,1]\n",
    "    return (probs >= threshold).astype(int), probs\n",
    "\n",
    "# Ejemplo (descomentar cuando tengas X_new):\n",
    "# model, cfg = load_model_and_config()\n",
    "# y_pred, y_prob = predict_with_threshold(X_new, model, cfg[\"threshold\"])\n",
    "# print(\"Preds:\", y_pred[:10], \"Probs:\", y_prob[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db614f",
   "metadata": {},
   "source": [
    "## Housekeeping (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODELS_DIR = Path(\"models\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "existing = list(MODELS_DIR.glob(\"*.pkl\"))\n",
    "print(\"Archivos actuales en models/:\")\n",
    "for p in existing:\n",
    "    print(\"-\", p.name)\n",
    "print(\"\\nSugerencia: conservar sólo los modelos calibrados y registrar métricas en registry.json\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
