# Project Structure

This document provides an overview of the organized project structure for the Exoplanet Detection using AI system.

## ğŸ“ Directory Layout

```
Exoplanet-detection-using-AI/
â”œâ”€â”€ README.md                           # Main project documentation
â”œâ”€â”€ LICENSE                             # MIT License
â”œâ”€â”€ CONTRIBUTING.md                     # Contribution guidelines
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ features.json                       # Feature list for model inference
â”‚
â”œâ”€â”€ data/                              # Dataset files
â”‚   â”œâ”€â”€ cumulative_2025.10.04_05.21.55.csv    # Kepler cumulative catalog
â”‚   â”œâ”€â”€ k2pandc_2025.10.04_05.29.43.csv       # K2 planet candidates
â”‚   â””â”€â”€ TOI_2025.10.04_05.29.26.csv           # TESS Objects of Interest
â”‚
â”œâ”€â”€ notebooks/                         # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_exoplanet_detection_binary.ipynb           # Binary classification
â”‚   â”œâ”€â”€ 02_false_positive_detection.ipynb             # False positive handling
â”‚   â””â”€â”€ archived/                      # Previous versions
â”‚       â”œâ”€â”€ exoplanet_ml_final_fast.ipynb
â”‚       â”œâ”€â”€ exoplanet_ml_final.ipynb
â”‚       â””â”€â”€ kono/                      # Alternative implementations
â”‚           â”œâ”€â”€ modelCumulativeKono copy.ipynb
â”‚           â””â”€â”€ modelTOIKono.ipynb
â”‚
â”œâ”€â”€ src/                               # Source code modules
â”‚   â”œâ”€â”€ __init__.py                    # Package initialization
â”‚   â”œâ”€â”€ data_preprocessing.py          # Data cleaning and preprocessing
â”‚   â”œâ”€â”€ feature_engineering.py        # Feature creation and selection
â”‚   â”œâ”€â”€ model_training.py             # Model training utilities
â”‚   â””â”€â”€ evaluation.py                 # Model evaluation metrics
â”‚
â”œâ”€â”€ models/                            # Trained models and artifacts
â”‚   â”œâ”€â”€ production/                    # Production-ready models
â”‚   â”‚   â””â”€â”€ sub_models/               # Final trained models
â”‚   â”‚       â”œâ”€â”€ adaboost.pkl
â”‚   â”‚       â”œâ”€â”€ extra_trees.pkl
â”‚   â”‚       â”œâ”€â”€ random_forest.pkl
â”‚   â”‚       â””â”€â”€ stacking.pkl
â”‚   â”œâ”€â”€ experiments/                   # Experimental models
â”‚   â”‚   â”œâ”€â”€ fps/                      # False positive experiments
â”‚   â”‚   â”‚   â””â”€â”€ experimento/          # Specific experiment runs
â”‚   â”‚   â””â”€â”€ analysis/                 # Analysis artifacts
â”‚   â”‚       â”œâ”€â”€ cv_summary.csv
â”‚   â”‚       â”œâ”€â”€ feature_importances_by_permutation.csv
â”‚   â”‚       â”œâ”€â”€ feature_importances_by_weight.csv
â”‚   â”‚       â””â”€â”€ feature_importances_comparison.csv
â”‚   â””â”€â”€ archived/                     # Previous model versions
â”‚       â”œâ”€â”€ discontinued_models/      # Older model implementations
â”‚       â””â”€â”€ sub_models/              # Legacy models
â”‚
â”œâ”€â”€ docs/                             # Documentation
â”‚   â”œâ”€â”€ API.md                        # Technical API documentation
â”‚   â”œâ”€â”€ CHANGELOG.md                  # Version history
â”‚   â””â”€â”€ DEPLOYMENT.md                 # Deployment instructions
â”‚
â””â”€â”€ .git/                             # Git version control
    â”œâ”€â”€ .gitignore                    # Git ignore rules
    â””â”€â”€ .gitattributes               # Git attributes
```

## ğŸ“‹ File Descriptions

### Core Files

- **README.md**: Comprehensive project overview, installation instructions, and usage guide
- **LICENSE**: MIT License for open-source distribution
- **CONTRIBUTING.md**: Guidelines for contributors
- **requirements.txt**: Python package dependencies with versions
- **features.json**: List of feature columns used by trained models

### Data Directory (`data/`)

Contains astronomical datasets from NASA missions:
- **Kepler Cumulative Catalog**: Complete list of Kepler Objects of Interest
- **K2 Campaign Data**: Targets from K2 extended mission
- **TESS Objects of Interest**: Candidates from TESS mission

### Notebooks Directory (`notebooks/`)

Organized Jupyter notebooks for different aspects of the project:
- **Binary Classification**: Main exoplanet vs candidate classification
- **False Positive Detection**: Enhanced classification including false positives (includes visualization and analysis)
- **Archived**: Historical notebooks and alternative implementations

### Source Code (`src/`)

Modular Python codebase:
- **data_preprocessing.py**: Data loading, cleaning, and preparation utilities
- **feature_engineering.py**: Feature creation, selection, and transformation
- **model_training.py**: Machine learning model training and management
- **evaluation.py**: Comprehensive model evaluation and visualization tools

### Models Directory (`models/`)

Organized model storage:
- **production/**: Finalized models ready for deployment
- **experiments/**: Experimental models and analysis results
- **archived/**: Previous model versions and discontinued approaches

### Documentation (`docs/`)

Technical documentation:
- **API.md**: Detailed API documentation for code modules
- **CHANGELOG.md**: Version history and changes
- **DEPLOYMENT.md**: Instructions for deploying models

## ğŸ”„ Workflow

### Development Workflow

1. **Data Exploration**: Start with the exploration sections in `notebooks/01_exoplanet_detection_binary.ipynb`
2. **Binary Classification**: Implement basic classification in `notebooks/01_exoplanet_detection_binary.ipynb`
3. **Advanced Classification**: Enhance with false positive detection in `notebooks/02_false_positive_detection.ipynb`
4. **Modular Development**: Extract reusable code to `src/` modules
5. **Model Management**: Save final models to `models/production/`

### Data Science Pipeline

```
Raw Data (data/) 
    â†“
Data Preprocessing (src/data_preprocessing.py)
    â†“
Feature Engineering (src/feature_engineering.py)
    â†“
Model Training (src/model_training.py)
    â†“
Model Evaluation (src/evaluation.py)
    â†“
Production Models (models/production/)
```

## ğŸ¯ Best Practices

### Code Organization

- **Modular Design**: Separate concerns into different modules
- **Reusability**: Common functions in `src/` modules
- **Documentation**: Comprehensive docstrings and comments
- **Version Control**: Track changes with meaningful commit messages

### Data Management

- **Raw Data Preservation**: Keep original datasets unchanged
- **Reproducibility**: Fixed random seeds and versioned dependencies
- **Backup**: Multiple copies of important datasets
- **Documentation**: Clear data source attribution

### Model Management

- **Version Control**: Track model versions and performance
- **Artifacts**: Save scalers, feature lists, and metadata
- **Organization**: Separate experimental from production models
- **Documentation**: Record training procedures and hyperparameters

## ğŸ”§ Maintenance

### Regular Tasks

- **Dependency Updates**: Keep packages current with security patches
- **Model Retraining**: Retrain with new data as available
- **Performance Monitoring**: Track model performance over time
- **Documentation Updates**: Keep documentation current with code changes

### Quality Assurance

- **Code Review**: Review all changes before merging
- **Testing**: Run notebooks end-to-end before releases
- **Validation**: Verify model performance on new data
- **Backup**: Regular backups of models and results

This organized structure ensures the project is maintainable, scalable, and suitable for professional development and deployment.